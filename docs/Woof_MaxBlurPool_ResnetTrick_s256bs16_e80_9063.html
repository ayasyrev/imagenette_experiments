---

title: ResnetTrick_s256bs16_e80


keywords: fastai
sidebar: home_sidebar

summary: "size 256 bs 16 80 epochs runs."
description: "size 256 bs 16 80 epochs runs."
nb_path: "Imagenette_Nbs_1/Woof_MaxBlurPool_ResnetTrick_s256bs16_e80_9063.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: Imagenette_Nbs_1/Woof_MaxBlurPool_ResnetTrick_s256bs16_e80_9063.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="setup-and-imports">setup and imports<a class="anchor-link" href="#setup-and-imports"> </a></h1>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">kornia.contrib</span> <span class="kn">import</span> <span class="n">MaxBlurPool2d</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">fastai.basic_train</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">fastai.vision</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">fastai.script</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">model_constructor.net</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">model_constructor.layers</span> <span class="kn">import</span> <span class="n">SimpleSelfAttention</span><span class="p">,</span> <span class="n">ConvLayer</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>  <span class="c1">#https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer</span>

  <span class="c1">#Ranger has now been used to capture 12 records on the FastAI leaderboard.</span>

  <span class="c1">#This version = 9.3.19  </span>

  <span class="c1">#Credits:</span>
  <span class="c1">#RAdam --&gt;  https://github.com/LiyuanLucasLiu/RAdam</span>
  <span class="c1">#Lookahead --&gt; rewritten by lessw2020, but big thanks to Github @LonePatient and @RWightman for ideas from their code.</span>
  <span class="c1">#Lookahead paper --&gt; MZhang,G Hinton  https://arxiv.org/abs/1907.08610</span>

  <span class="c1">#summary of changes: </span>
  <span class="c1">#full code integration with all updates at param level instead of group, moves slow weights into state dict (from generic weights), </span>
  <span class="c1">#supports group learning rates (thanks @SHolderbach), fixes sporadic load from saved model issues.</span>
  <span class="c1">#changes 8/31/19 - fix references to *self*.N_sma_threshold; </span>
                  <span class="c1">#changed eps to 1e-5 as better default than 1e-8.</span>

<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.optim.optimizer</span> <span class="kn">import</span> <span class="n">Optimizer</span><span class="p">,</span> <span class="n">required</span>
<span class="kn">import</span> <span class="nn">itertools</span> <span class="k">as</span> <span class="nn">it</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="utils">utils<a class="anchor-link" href="#utils"> </a></h1>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Mish</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mish activation loaded...&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>  
        <span class="c1">#save 1 second per epoch with no x= x*() and then return x...just inline it.</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">*</span><span class="p">(</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Ranger</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">N_sma_threshhold</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="o">.</span><span class="mi">95</span><span class="p">,</span><span class="mf">0.999</span><span class="p">),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="c1">#parameter checks</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">alpha</span> <span class="o">&lt;=</span> <span class="mf">1.0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Invalid slow update rate: </span><span class="si">{</span><span class="n">alpha</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="mi">1</span> <span class="o">&lt;=</span> <span class="n">k</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Invalid lookahead steps: </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">lr</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Invalid Learning Rate: </span><span class="si">{</span><span class="n">lr</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">eps</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Invalid eps: </span><span class="si">{</span><span class="n">eps</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

        <span class="c1">#parameter comments:</span>
        <span class="c1"># beta1 (momentum) of .95 seems to work better than .90...</span>
        <span class="c1">#N_sma_threshold of 5 seems better in testing than 4.</span>
        <span class="c1">#In both cases, worth testing on your dataset (.90 vs .95, 4 vs 5) to make sure which works best for you.</span>

        <span class="c1">#prep defaults and init torch.optim base</span>
        <span class="n">defaults</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">step_counter</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="n">betas</span><span class="p">,</span> <span class="n">N_sma_threshhold</span><span class="o">=</span><span class="n">N_sma_threshhold</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="n">eps</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">,</span><span class="n">defaults</span><span class="p">)</span>

        <span class="c1">#adjustable threshold</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">N_sma_threshhold</span> <span class="o">=</span> <span class="n">N_sma_threshhold</span>

        <span class="c1">#now we can get to work...</span>
        <span class="c1">#removed as we now use step from RAdam...no need for duplicate step counting</span>
        <span class="c1">#for group in self.param_groups:</span>
        <span class="c1">#    group[&quot;step_counter&quot;] = 0</span>
            <span class="c1">#print(&quot;group step counter init&quot;)</span>

        <span class="c1">#look ahead params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span> 

        <span class="c1">#radam buffer for state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">radam_buffer</span> <span class="o">=</span> <span class="p">[[</span><span class="kc">None</span><span class="p">,</span><span class="kc">None</span><span class="p">,</span><span class="kc">None</span><span class="p">]</span> <span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>

        <span class="c1">#self.first_run_check=0</span>

        <span class="c1">#lookahead weights</span>
        <span class="c1">#9/2/19 - lookahead param tensors have been moved to state storage.  </span>
        <span class="c1">#This should resolve issues with load/save where weights were left in GPU memory from first load, slowing down future runs.</span>

        <span class="c1">#self.slow_weights = [[p.clone().detach() for p in group[&#39;params&#39;]]</span>
        <span class="c1">#                     for group in self.param_groups]</span>

        <span class="c1">#don&#39;t use grad for lookahead weights</span>
        <span class="c1">#for w in it.chain(*self.slow_weights):</span>
        <span class="c1">#    w.requires_grad = False</span>

    <span class="k">def</span> <span class="nf">__setstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;set state called&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Ranger</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__setstate__</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">closure</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="c1">#note - below is commented out b/c I have other work that passes back the loss as a float, and thus not a callable closure.  </span>
        <span class="c1">#Uncomment if you need to use the actual closure...</span>

        <span class="c1">#if closure is not None:</span>
            <span class="c1">#loss = closure()</span>

        <span class="c1">#Evaluate averages and grad, update param tensors</span>
        <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>

            <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">group</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">]:</span>
                <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="n">grad</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">grad</span><span class="o">.</span><span class="n">is_sparse</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;Ranger optimizer does not support sparse gradients&#39;</span><span class="p">)</span>

                <span class="n">p_data_fp32</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

                <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">[</span><span class="n">p</span><span class="p">]</span>  <span class="c1">#get state dict for this param</span>

                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">state</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>   <span class="c1">#if first time to run...init dictionary with our desired entries</span>
                    <span class="c1">#if self.first_run_check==0:</span>
                        <span class="c1">#self.first_run_check=1</span>
                        <span class="c1">#print(&quot;Initializing slow buffer...should not see this at load from saved model!&quot;)</span>
                    <span class="n">state</span><span class="p">[</span><span class="s1">&#39;step&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
                    <span class="n">state</span><span class="p">[</span><span class="s1">&#39;exp_avg&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">p_data_fp32</span><span class="p">)</span>
                    <span class="n">state</span><span class="p">[</span><span class="s1">&#39;exp_avg_sq&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">p_data_fp32</span><span class="p">)</span>

                    <span class="c1">#look ahead weight storage now in state dict </span>
                    <span class="n">state</span><span class="p">[</span><span class="s1">&#39;slow_buffer&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
                    <span class="n">state</span><span class="p">[</span><span class="s1">&#39;slow_buffer&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

                <span class="k">else</span><span class="p">:</span>
                    <span class="n">state</span><span class="p">[</span><span class="s1">&#39;exp_avg&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s1">&#39;exp_avg&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">type_as</span><span class="p">(</span><span class="n">p_data_fp32</span><span class="p">)</span>
                    <span class="n">state</span><span class="p">[</span><span class="s1">&#39;exp_avg_sq&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s1">&#39;exp_avg_sq&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">type_as</span><span class="p">(</span><span class="n">p_data_fp32</span><span class="p">)</span>

                <span class="c1">#begin computations </span>
                <span class="n">exp_avg</span><span class="p">,</span> <span class="n">exp_avg_sq</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s1">&#39;exp_avg&#39;</span><span class="p">],</span> <span class="n">state</span><span class="p">[</span><span class="s1">&#39;exp_avg_sq&#39;</span><span class="p">]</span>
                <span class="n">beta1</span><span class="p">,</span> <span class="n">beta2</span> <span class="o">=</span> <span class="n">group</span><span class="p">[</span><span class="s1">&#39;betas&#39;</span><span class="p">]</span>

                <span class="c1">#compute variance mov avg</span>
                <span class="n">exp_avg_sq</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="n">beta2</span><span class="p">)</span><span class="o">.</span><span class="n">addcmul_</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta2</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">grad</span><span class="p">)</span>
                <span class="c1">#compute mean moving avg</span>
                <span class="n">exp_avg</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="n">beta1</span><span class="p">)</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta1</span><span class="p">,</span> <span class="n">grad</span><span class="p">)</span>

                <span class="n">state</span><span class="p">[</span><span class="s1">&#39;step&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>


                <span class="n">buffered</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">radam_buffer</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s1">&#39;step&#39;</span><span class="p">]</span> <span class="o">%</span> <span class="mi">10</span><span class="p">)]</span>
                <span class="k">if</span> <span class="n">state</span><span class="p">[</span><span class="s1">&#39;step&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">buffered</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
                    <span class="n">N_sma</span><span class="p">,</span> <span class="n">step_size</span> <span class="o">=</span> <span class="n">buffered</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">buffered</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">buffered</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s1">&#39;step&#39;</span><span class="p">]</span>
                    <span class="n">beta2_t</span> <span class="o">=</span> <span class="n">beta2</span> <span class="o">**</span> <span class="n">state</span><span class="p">[</span><span class="s1">&#39;step&#39;</span><span class="p">]</span>
                    <span class="n">N_sma_max</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta2</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
                    <span class="n">N_sma</span> <span class="o">=</span> <span class="n">N_sma_max</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">state</span><span class="p">[</span><span class="s1">&#39;step&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">beta2_t</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta2_t</span><span class="p">)</span>
                    <span class="n">buffered</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">N_sma</span>
                    <span class="k">if</span> <span class="n">N_sma</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_sma_threshhold</span><span class="p">:</span>
                        <span class="n">step_size</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta2_t</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">N_sma</span> <span class="o">-</span> <span class="mi">4</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">N_sma_max</span> <span class="o">-</span> <span class="mi">4</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">N_sma</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">N_sma</span> <span class="o">*</span> <span class="n">N_sma_max</span> <span class="o">/</span> <span class="p">(</span><span class="n">N_sma_max</span> <span class="o">-</span> <span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta1</span> <span class="o">**</span> <span class="n">state</span><span class="p">[</span><span class="s1">&#39;step&#39;</span><span class="p">])</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">step_size</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta1</span> <span class="o">**</span> <span class="n">state</span><span class="p">[</span><span class="s1">&#39;step&#39;</span><span class="p">])</span>
                    <span class="n">buffered</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">step_size</span>

                <span class="k">if</span> <span class="n">group</span><span class="p">[</span><span class="s1">&#39;weight_decay&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">p_data_fp32</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="o">-</span><span class="n">group</span><span class="p">[</span><span class="s1">&#39;weight_decay&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">group</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">],</span> <span class="n">p_data_fp32</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">N_sma</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_sma_threshhold</span><span class="p">:</span>
                    <span class="n">denom</span> <span class="o">=</span> <span class="n">exp_avg_sq</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">group</span><span class="p">[</span><span class="s1">&#39;eps&#39;</span><span class="p">])</span>
                    <span class="n">p_data_fp32</span><span class="o">.</span><span class="n">addcdiv_</span><span class="p">(</span><span class="o">-</span><span class="n">step_size</span> <span class="o">*</span> <span class="n">group</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">],</span> <span class="n">exp_avg</span><span class="p">,</span> <span class="n">denom</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">p_data_fp32</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="o">-</span><span class="n">step_size</span> <span class="o">*</span> <span class="n">group</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">],</span> <span class="n">exp_avg</span><span class="p">)</span>

                <span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">p_data_fp32</span><span class="p">)</span>

                <span class="c1">#integrated look ahead...</span>
                <span class="c1">#we do it at the param level instead of group level</span>
                <span class="k">if</span> <span class="n">state</span><span class="p">[</span><span class="s1">&#39;step&#39;</span><span class="p">]</span> <span class="o">%</span> <span class="n">group</span><span class="p">[</span><span class="s1">&#39;k&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">slow_p</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s1">&#39;slow_buffer&#39;</span><span class="p">]</span> <span class="c1">#get access to slow param tensor</span>
                    <span class="n">slow_p</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">data</span> <span class="o">-</span> <span class="n">slow_p</span><span class="p">)</span>  <span class="c1">#(fast weights - slow weights) * alpha</span>
                    <span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">slow_p</span><span class="p">)</span>  <span class="c1">#copy interpolated weights to RAdam param tensor</span>

        <span class="k">return</span> <span class="n">loss</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_data</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">woof</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">workers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">woof</span><span class="p">:</span>
        <span class="n">path</span> <span class="o">=</span> <span class="n">URLs</span><span class="o">.</span><span class="n">IMAGEWOOF</span>    <span class="c1"># if woof </span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">path</span> <span class="o">=</span> <span class="n">URLs</span><span class="o">.</span><span class="n">IMAGENETTE</span>
    <span class="n">path</span> <span class="o">=</span> <span class="n">untar_data</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;data path  &#39;</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span>
    <span class="n">n_gpus</span> <span class="o">=</span> <span class="n">num_distrib</span><span class="p">()</span> <span class="ow">or</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">workers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">workers</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">num_cpus</span><span class="p">()</span><span class="o">//</span><span class="n">n_gpus</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">ImageList</span><span class="o">.</span><span class="n">from_folder</span><span class="p">(</span><span class="n">path</span><span class="p">)</span><span class="o">.</span><span class="n">split_by_folder</span><span class="p">(</span><span class="n">valid</span><span class="o">=</span><span class="s1">&#39;val&#39;</span><span class="p">)</span>
            <span class="o">.</span><span class="n">label_from_folder</span><span class="p">()</span><span class="o">.</span><span class="n">transform</span><span class="p">(([</span><span class="n">flip_lr</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)],</span> <span class="p">[]),</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>
            <span class="o">.</span><span class="n">databunch</span><span class="p">(</span><span class="n">bs</span><span class="o">=</span><span class="n">bs</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">workers</span><span class="p">)</span>
            <span class="o">.</span><span class="n">presize</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="p">(</span><span class="mf">0.35</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
            <span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">imagenet_stats</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_learn</span><span class="p">(</span>
        <span class="n">gpu</span><span class="p">:</span><span class="n">Param</span><span class="p">(</span><span class="s2">&quot;GPU to run on&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">woof</span><span class="p">:</span> <span class="n">Param</span><span class="p">(</span><span class="s2">&quot;Use imagewoof (otherwise imagenette)&quot;</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">size</span><span class="p">:</span> <span class="n">Param</span><span class="p">(</span><span class="s2">&quot;Size (px: 128,192,224)&quot;</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
        <span class="n">alpha</span><span class="p">:</span> <span class="n">Param</span><span class="p">(</span><span class="s2">&quot;Alpha&quot;</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> 
        <span class="n">mom</span><span class="p">:</span> <span class="n">Param</span><span class="p">(</span><span class="s2">&quot;Momentum&quot;</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="c1">#? 0.9</span>
        <span class="n">eps</span><span class="p">:</span> <span class="n">Param</span><span class="p">(</span><span class="s2">&quot;epsilon&quot;</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span>
        <span class="n">bs</span><span class="p">:</span> <span class="n">Param</span><span class="p">(</span><span class="s2">&quot;Batch size&quot;</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
        <span class="n">mixup</span><span class="p">:</span> <span class="n">Param</span><span class="p">(</span><span class="s2">&quot;Mixup&quot;</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span>
        <span class="n">opt</span><span class="p">:</span> <span class="n">Param</span><span class="p">(</span><span class="s2">&quot;Optimizer (adam,rms,sgd)&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span><span class="o">=</span><span class="s1">&#39;ranger&#39;</span><span class="p">,</span>
        <span class="n">sa</span><span class="p">:</span> <span class="n">Param</span><span class="p">(</span><span class="s2">&quot;Self-attention&quot;</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">sym</span><span class="p">:</span> <span class="n">Param</span><span class="p">(</span><span class="s2">&quot;Symmetry for self-attention&quot;</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Param</span><span class="p">(</span><span class="s1">&#39;model as partial&#39;</span><span class="p">,</span> <span class="n">callable</span><span class="p">)</span> <span class="o">=</span> <span class="n">xresnet50</span>
        <span class="p">):</span>
 
    <span class="k">if</span>   <span class="n">opt</span><span class="o">==</span><span class="s1">&#39;adam&#39;</span> <span class="p">:</span> <span class="n">opt_func</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="n">mom</span><span class="p">,</span><span class="n">alpha</span><span class="p">),</span> <span class="n">eps</span><span class="o">=</span><span class="n">eps</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">opt</span><span class="o">==</span><span class="s1">&#39;ranger&#39;</span>  <span class="p">:</span> <span class="n">opt_func</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">Ranger</span><span class="p">,</span>  <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="n">mom</span><span class="p">,</span><span class="n">alpha</span><span class="p">),</span> <span class="n">eps</span><span class="o">=</span><span class="n">eps</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">woof</span><span class="p">,</span> <span class="n">bs</span><span class="p">)</span>
    <span class="n">learn</span> <span class="o">=</span> <span class="p">(</span><span class="n">Learner</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">model</span><span class="p">(),</span> <span class="n">wd</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span> <span class="n">opt_func</span><span class="o">=</span><span class="n">opt_func</span><span class="p">,</span>
             <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">accuracy</span><span class="p">,</span><span class="n">top_k_accuracy</span><span class="p">],</span>
             <span class="n">bn_wd</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">true_wd</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
             <span class="n">loss_func</span> <span class="o">=</span> <span class="n">LabelSmoothingCrossEntropy</span><span class="p">(),))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Learn path&#39;</span><span class="p">,</span> <span class="n">learn</span><span class="o">.</span><span class="n">path</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">mixup</span><span class="p">:</span> <span class="n">learn</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">mixup</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">mixup</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">learn</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="n">learn</span><span class="p">):</span>
    <span class="n">learn</span><span class="o">.</span><span class="n">recorder</span><span class="o">.</span><span class="n">plot_losses</span><span class="p">()</span>
    <span class="n">learn</span><span class="o">.</span><span class="n">recorder</span><span class="o">.</span><span class="n">plot_metrics</span><span class="p">()</span>
    <span class="n">learn</span><span class="o">.</span><span class="n">recorder</span><span class="o">.</span><span class="n">plot_lr</span><span class="p">(</span><span class="n">show_moms</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">Learner</span><span class="o">.</span><span class="n">plot</span> <span class="o">=</span> <span class="n">plot</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="ResBlock">ResBlock<a class="anchor-link" href="#ResBlock"> </a></h1>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">NewResBlock</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">expansion</span><span class="p">,</span> <span class="n">ni</span><span class="p">,</span> <span class="n">nh</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                 <span class="n">conv_layer</span><span class="o">=</span><span class="n">ConvLayer</span><span class="p">,</span> <span class="n">act_fn</span><span class="o">=</span><span class="n">act_fn</span><span class="p">,</span>
<span class="c1">#                  pool=nn.AvgPool2d(2, ceil_mode=True), sa=False,sym=False):</span>
                 <span class="n">pool</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">AvgPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">sa</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">sym</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">zero_bn</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">nf</span><span class="p">,</span><span class="n">ni</span> <span class="o">=</span> <span class="n">nh</span><span class="o">*</span><span class="n">expansion</span><span class="p">,</span><span class="n">ni</span><span class="o">*</span><span class="n">expansion</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reduce</span> <span class="o">=</span> <span class="n">noop</span> <span class="k">if</span> <span class="n">stride</span><span class="o">==</span><span class="mi">1</span> <span class="k">else</span> <span class="n">pool</span>
        <span class="n">layers</span>  <span class="o">=</span> <span class="p">[(</span><span class="sa">f</span><span class="s2">&quot;conv_0&quot;</span><span class="p">,</span> <span class="n">conv_layer</span><span class="p">(</span><span class="n">ni</span><span class="p">,</span> <span class="n">nh</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">act_fn</span><span class="o">=</span><span class="n">act_fn</span><span class="p">)),</span>
                   <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;conv_1&quot;</span><span class="p">,</span> <span class="n">conv_layer</span><span class="p">(</span><span class="n">nh</span><span class="p">,</span> <span class="n">nf</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">zero_bn</span><span class="o">=</span><span class="n">zero_bn</span><span class="p">,</span> <span class="n">act</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
        <span class="p">]</span> <span class="k">if</span> <span class="n">expansion</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="p">[</span>
                   <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;conv_0&quot;</span><span class="p">,</span><span class="n">conv_layer</span><span class="p">(</span><span class="n">ni</span><span class="p">,</span> <span class="n">nh</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">act_fn</span><span class="o">=</span><span class="n">act_fn</span><span class="p">)),</span>
                   <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;conv_1&quot;</span><span class="p">,</span><span class="n">conv_layer</span><span class="p">(</span><span class="n">nh</span><span class="p">,</span> <span class="n">nh</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">act_fn</span><span class="o">=</span><span class="n">act_fn</span><span class="p">)),</span> <span class="c1">#!!!</span>
                   <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;conv_2&quot;</span><span class="p">,</span><span class="n">conv_layer</span><span class="p">(</span><span class="n">nh</span><span class="p">,</span> <span class="n">nf</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">zero_bn</span><span class="o">=</span><span class="n">zero_bn</span><span class="p">,</span> <span class="n">act</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
        <span class="p">]</span>
        <span class="k">if</span> <span class="n">sa</span><span class="p">:</span> <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;sa&#39;</span><span class="p">,</span> <span class="n">SimpleSelfAttention</span><span class="p">(</span><span class="n">nf</span><span class="p">,</span><span class="n">ks</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">sym</span><span class="o">=</span><span class="n">sym</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">convs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">OrderedDict</span><span class="p">(</span><span class="n">layers</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">idconv</span> <span class="o">=</span> <span class="n">noop</span> <span class="k">if</span> <span class="n">ni</span><span class="o">==</span><span class="n">nf</span> <span class="k">else</span> <span class="n">conv_layer</span><span class="p">(</span><span class="n">ni</span><span class="p">,</span> <span class="n">nf</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">act</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">merge</span> <span class="o">=</span><span class="n">act_fn</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span> 
        <span class="n">o</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="p">(</span><span class="n">o</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">idconv</span><span class="p">(</span><span class="n">o</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Model-Constructor">Model Constructor<a class="anchor-link" href="#Model-Constructor"> </a></h1>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">xresnet50</span><span class="p">(</span><span class="n">c_out</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">block</span> <span class="o">=</span> <span class="n">NewResBlock</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pool</span> <span class="o">=</span> <span class="n">MaxBlurPool2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">pool</span>
<span class="n">model</span><span class="o">.</span><span class="n">stem_pool</span> <span class="o">=</span> <span class="n">pool</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">stem_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">64</span><span class="p">]</span>

<span class="n">model</span><span class="o">.</span><span class="n">act_fn</span><span class="o">=</span> <span class="n">Mish</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">sa</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Mish activation loaded...
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="repr-model">repr model<a class="anchor-link" href="#repr-model"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Sequential(
  model xresnet50
  (stem): Sequential(
    (conv_0): ConvLayer(
      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act_fn): Mish()
    )
    (conv_1): ConvLayer(
      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act_fn): Mish()
    )
    (conv_2): ConvLayer(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act_fn): Mish()
    )
    (stem_pool): MaxBlurPool2d()
  )
  (body): Sequential(
    (l_0): Sequential(
      (bl_0): NewResBlock(
        (convs): Sequential(
          (conv_0): ConvLayer(
            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_fn): Mish()
          )
          (conv_1): ConvLayer(
            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_fn): Mish()
          )
          (conv_2): ConvLayer(
            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (idconv): ConvLayer(
          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (merge): Mish()
      )
      (bl_1): NewResBlock(
        (convs): Sequential(
          (conv_0): ConvLayer(
            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_fn): Mish()
          )
          (conv_1): ConvLayer(
            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_fn): Mish()
          )
          (conv_2): ConvLayer(
            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (merge): Mish()
      )
      (bl_2): NewResBlock(
        (convs): Sequential(
          (conv_0): ConvLayer(
            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_fn): Mish()
          )
          (conv_1): ConvLayer(
            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_fn): Mish()
          )
          (conv_2): ConvLayer(
            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (sa): SimpleSelfAttention(
            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
          )
        )
        (merge): Mish()
      )
    )
    (l_1): Sequential(
      (bl_0): NewResBlock(
        (reduce): MaxBlurPool2d()
        (convs): Sequential(
          (conv_0): ConvLayer(
            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_fn): Mish()
          )
          (conv_1): ConvLayer(
            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_fn): Mish()
          )
          (conv_2): ConvLayer(
            (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (idconv): ConvLayer(
          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (merge): Mish()
      )
      (bl_1): NewResBlock(
        (convs): Sequential(
          (conv_0): ConvLayer(
            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_fn): Mish()
          )
          (conv_1): ConvLayer(
            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_fn): Mish()
          )
          (conv_2): ConvLayer(
            (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (merge): Mish()
      )
      (bl_2): NewResBlock(
        (convs): Sequential(
          (conv_0): ConvLayer(
            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_fn): Mish()
          )
          (conv_1): ConvLayer(
            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_fn): Mish()
          )
          (conv_2): ConvLayer(
            (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (merge): Mish()
      )
      (bl_3): NewResBlock(
        (convs): Sequential(
          (conv_0): ConvLayer(
            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_fn): Mish()
          )
          (conv_1): ConvLayer(
            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_fn): Mish()
          )
          (conv_2): ConvLayer(
            (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (merge): Mish()
      )
    )
    (l_2): Sequential(
      (bl_0): NewResBlock(
        (reduce): MaxBlurPool2d()
        (convs): Sequential(
          (conv_0): ConvLayer(
            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_fn): Mish()
          )
          (conv_1): ConvLayer(
            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_fn): Mish()
          )
          (conv_2): ConvLayer(
            (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (idconv): ConvLayer(
          (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (merge): Mish()
      )
      (bl_1): NewResBlock(
        (convs): Sequential(
          (conv_0): ConvLayer(
            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_fn): Mish()
          )
          (conv_1): ConvLayer(
            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_fn): Mish()
          )
          (conv_2): ConvLayer(
            (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (merge): Mish()
      )
      (bl_2): NewResBlock(
        (convs): Sequential(
          (conv_0): ConvLayer(
            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_fn): Mish()
          )
          (conv_1): ConvLayer(
            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_fn): Mish()
          )
          (conv_2): ConvLayer(
            (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (merge): Mish()
      )
      (bl_3): NewResBlock(
        (convs): Sequential(
          (conv_0): ConvLayer(
            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_fn): Mish()
          )
          (conv_1): ConvLayer(
            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_fn): Mish()
          )
          (conv_2): ConvLayer(
            (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (merge): Mish()
      )
      (bl_4): NewResBlock(
        (convs): Sequential(
          (conv_0): ConvLayer(
            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_fn): Mish()
          )
          (conv_1): ConvLayer(
            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_fn): Mish()
          )
          (conv_2): ConvLayer(
            (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (merge): Mish()
      )
      (bl_5): NewResBlock(
        (convs): Sequential(
          (conv_0): ConvLayer(
            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_fn): Mish()
          )
          (conv_1): ConvLayer(
            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_fn): Mish()
          )
          (conv_2): ConvLayer(
            (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (merge): Mish()
      )
    )
    (l_3): Sequential(
      (bl_0): NewResBlock(
        (reduce): MaxBlurPool2d()
        (convs): Sequential(
          (conv_0): ConvLayer(
            (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_fn): Mish()
          )
          (conv_1): ConvLayer(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_fn): Mish()
          )
          (conv_2): ConvLayer(
            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (idconv): ConvLayer(
          (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (merge): Mish()
      )
      (bl_1): NewResBlock(
        (convs): Sequential(
          (conv_0): ConvLayer(
            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_fn): Mish()
          )
          (conv_1): ConvLayer(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_fn): Mish()
          )
          (conv_2): ConvLayer(
            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (merge): Mish()
      )
      (bl_2): NewResBlock(
        (convs): Sequential(
          (conv_0): ConvLayer(
            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_fn): Mish()
          )
          (conv_1): ConvLayer(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_fn): Mish()
          )
          (conv_2): ConvLayer(
            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (merge): Mish()
      )
    )
  )
  (head): Sequential(
    (pool): AdaptiveAvgPool2d(output_size=1)
    (flat): Flatten()
    (fc): Linear(in_features=2048, out_features=10, bias=True)
  )
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">stem</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Sequential(
  (conv_0): ConvLayer(
    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act_fn): Mish()
  )
  (conv_1): ConvLayer(
    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act_fn): Mish()
  )
  (conv_2): ConvLayer(
    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act_fn): Mish()
  )
  (stem_pool): MaxBlurPool2d()
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">body</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Sequential(
  (l_0): Sequential(
    (bl_0): NewResBlock(
      (convs): Sequential(
        (conv_0): ConvLayer(
          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_fn): Mish()
        )
        (conv_1): ConvLayer(
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_fn): Mish()
        )
        (conv_2): ConvLayer(
          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (idconv): ConvLayer(
        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (merge): Mish()
    )
    (bl_1): NewResBlock(
      (convs): Sequential(
        (conv_0): ConvLayer(
          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_fn): Mish()
        )
        (conv_1): ConvLayer(
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_fn): Mish()
        )
        (conv_2): ConvLayer(
          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (merge): Mish()
    )
    (bl_2): NewResBlock(
      (convs): Sequential(
        (conv_0): ConvLayer(
          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_fn): Mish()
        )
        (conv_1): ConvLayer(
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_fn): Mish()
        )
        (conv_2): ConvLayer(
          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (sa): SimpleSelfAttention(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
        )
      )
      (merge): Mish()
    )
  )
  (l_1): Sequential(
    (bl_0): NewResBlock(
      (reduce): MaxBlurPool2d()
      (convs): Sequential(
        (conv_0): ConvLayer(
          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_fn): Mish()
        )
        (conv_1): ConvLayer(
          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_fn): Mish()
        )
        (conv_2): ConvLayer(
          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (idconv): ConvLayer(
        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (merge): Mish()
    )
    (bl_1): NewResBlock(
      (convs): Sequential(
        (conv_0): ConvLayer(
          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_fn): Mish()
        )
        (conv_1): ConvLayer(
          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_fn): Mish()
        )
        (conv_2): ConvLayer(
          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (merge): Mish()
    )
    (bl_2): NewResBlock(
      (convs): Sequential(
        (conv_0): ConvLayer(
          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_fn): Mish()
        )
        (conv_1): ConvLayer(
          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_fn): Mish()
        )
        (conv_2): ConvLayer(
          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (merge): Mish()
    )
    (bl_3): NewResBlock(
      (convs): Sequential(
        (conv_0): ConvLayer(
          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_fn): Mish()
        )
        (conv_1): ConvLayer(
          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_fn): Mish()
        )
        (conv_2): ConvLayer(
          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (merge): Mish()
    )
  )
  (l_2): Sequential(
    (bl_0): NewResBlock(
      (reduce): MaxBlurPool2d()
      (convs): Sequential(
        (conv_0): ConvLayer(
          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_fn): Mish()
        )
        (conv_1): ConvLayer(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_fn): Mish()
        )
        (conv_2): ConvLayer(
          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (idconv): ConvLayer(
        (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (merge): Mish()
    )
    (bl_1): NewResBlock(
      (convs): Sequential(
        (conv_0): ConvLayer(
          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_fn): Mish()
        )
        (conv_1): ConvLayer(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_fn): Mish()
        )
        (conv_2): ConvLayer(
          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (merge): Mish()
    )
    (bl_2): NewResBlock(
      (convs): Sequential(
        (conv_0): ConvLayer(
          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_fn): Mish()
        )
        (conv_1): ConvLayer(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_fn): Mish()
        )
        (conv_2): ConvLayer(
          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (merge): Mish()
    )
    (bl_3): NewResBlock(
      (convs): Sequential(
        (conv_0): ConvLayer(
          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_fn): Mish()
        )
        (conv_1): ConvLayer(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_fn): Mish()
        )
        (conv_2): ConvLayer(
          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (merge): Mish()
    )
    (bl_4): NewResBlock(
      (convs): Sequential(
        (conv_0): ConvLayer(
          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_fn): Mish()
        )
        (conv_1): ConvLayer(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_fn): Mish()
        )
        (conv_2): ConvLayer(
          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (merge): Mish()
    )
    (bl_5): NewResBlock(
      (convs): Sequential(
        (conv_0): ConvLayer(
          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_fn): Mish()
        )
        (conv_1): ConvLayer(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_fn): Mish()
        )
        (conv_2): ConvLayer(
          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (merge): Mish()
    )
  )
  (l_3): Sequential(
    (bl_0): NewResBlock(
      (reduce): MaxBlurPool2d()
      (convs): Sequential(
        (conv_0): ConvLayer(
          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_fn): Mish()
        )
        (conv_1): ConvLayer(
          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_fn): Mish()
        )
        (conv_2): ConvLayer(
          (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (idconv): ConvLayer(
        (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (merge): Mish()
    )
    (bl_1): NewResBlock(
      (convs): Sequential(
        (conv_0): ConvLayer(
          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_fn): Mish()
        )
        (conv_1): ConvLayer(
          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_fn): Mish()
        )
        (conv_2): ConvLayer(
          (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (merge): Mish()
    )
    (bl_2): NewResBlock(
      (convs): Sequential(
        (conv_0): ConvLayer(
          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_fn): Mish()
        )
        (conv_1): ConvLayer(
          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_fn): Mish()
        )
        (conv_2): ConvLayer(
          (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (merge): Mish()
    )
  )
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">head</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Sequential(
  (pool): AdaptiveAvgPool2d(output_size=1)
  (flat): Flatten()
  (fc): Linear(in_features=2048, out_features=10, bias=True)
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Parameters">Parameters<a class="anchor-link" href="#Parameters"> </a></h1>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.004</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">80</span>
<span class="n">moms</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.95</span><span class="p">,</span><span class="mf">0.95</span><span class="p">)</span>
<span class="n">start_pct</span> <span class="o">=</span> <span class="mf">0.4</span>
<span class="n">size</span><span class="o">=</span><span class="mi">256</span>
<span class="n">bs</span><span class="o">=</span><span class="mi">16</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Lr-find">Lr find<a class="anchor-link" href="#Lr-find"> </a></h1>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">get_learn</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span><span class="n">bs</span><span class="o">=</span><span class="n">bs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>data path   /notebooks/data/imagewoof2
Learn path /notebooks/data/imagewoof2
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

    <div>
        <style>
            /* Turns off some styling */
            progress {
                /* gets rid of default border in Firefox and Opera. */
                border: none;
                /* Needs to be in here for Safari polyfill so background images work as expected. */
                background-size: auto;
            }
            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
                background: #F44336;
            }
        </style>
      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>
      0.00% [0/1 00:00<00:00]
    </div>
    
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>top_k_accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
  </tbody>
</table><p>

    <div>
        <style>
            /* Turns off some styling */
            progress {
                /* gets rid of default border in Firefox and Opera. */
                border: none;
                /* Needs to be in here for Safari polyfill so background images work as expected. */
                background-size: auto;
            }
            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
                background: #F44336;
            }
        </style>
      <progress value='92' class='' max='564', style='width:300px; height:20px; vertical-align: middle;'></progress>
      16.31% [92/564 00:25<02:11 7.9913]
    </div>
    
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>set state called
LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">recorder</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="epochs-80-9045">epochs 80 9045<a class="anchor-link" href="#epochs-80-9045"> </a></h1>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">get_learn</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span><span class="n">bs</span><span class="o">=</span><span class="n">bs</span><span class="p">,</span> <span class="n">mixup</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_fc</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">moms</span><span class="p">,</span><span class="n">start_pct</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>data path   /notebooks/data/imagewoof2
Learn path /notebooks/data/imagewoof2
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>top_k_accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.069963</td>
      <td>1.887730</td>
      <td>0.370323</td>
      <td>0.865106</td>
      <td>02:58</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.898108</td>
      <td>1.707023</td>
      <td>0.461441</td>
      <td>0.906592</td>
      <td>03:02</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.716372</td>
      <td>1.530373</td>
      <td>0.555867</td>
      <td>0.929244</td>
      <td>03:02</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.641991</td>
      <td>1.408172</td>
      <td>0.610842</td>
      <td>0.941970</td>
      <td>03:04</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.527325</td>
      <td>1.322380</td>
      <td>0.646220</td>
      <td>0.955205</td>
      <td>03:03</td>
    </tr>
    <tr>
      <td>5</td>
      <td>1.508081</td>
      <td>1.196630</td>
      <td>0.721558</td>
      <td>0.963604</td>
      <td>03:04</td>
    </tr>
    <tr>
      <td>6</td>
      <td>1.459687</td>
      <td>1.125820</td>
      <td>0.761008</td>
      <td>0.972512</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>7</td>
      <td>1.379063</td>
      <td>1.104505</td>
      <td>0.762026</td>
      <td>0.972258</td>
      <td>03:04</td>
    </tr>
    <tr>
      <td>8</td>
      <td>1.386399</td>
      <td>1.099225</td>
      <td>0.755154</td>
      <td>0.973785</td>
      <td>03:04</td>
    </tr>
    <tr>
      <td>9</td>
      <td>1.382449</td>
      <td>1.060668</td>
      <td>0.782642</td>
      <td>0.973021</td>
      <td>03:04</td>
    </tr>
    <tr>
      <td>10</td>
      <td>1.296459</td>
      <td>1.038948</td>
      <td>0.794095</td>
      <td>0.978875</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>11</td>
      <td>1.302117</td>
      <td>0.993421</td>
      <td>0.809875</td>
      <td>0.976584</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>12</td>
      <td>1.287744</td>
      <td>1.033597</td>
      <td>0.792059</td>
      <td>0.971749</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>13</td>
      <td>1.237440</td>
      <td>0.967098</td>
      <td>0.820820</td>
      <td>0.980402</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>14</td>
      <td>1.200596</td>
      <td>0.975583</td>
      <td>0.815984</td>
      <td>0.978875</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>15</td>
      <td>1.225988</td>
      <td>0.957756</td>
      <td>0.824383</td>
      <td>0.984220</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>16</td>
      <td>1.209110</td>
      <td>0.952143</td>
      <td>0.830237</td>
      <td>0.978366</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>17</td>
      <td>1.197131</td>
      <td>0.922202</td>
      <td>0.841690</td>
      <td>0.982184</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>18</td>
      <td>1.182589</td>
      <td>0.917959</td>
      <td>0.841690</td>
      <td>0.988292</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>19</td>
      <td>1.130615</td>
      <td>0.924858</td>
      <td>0.843981</td>
      <td>0.982947</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>20</td>
      <td>1.137672</td>
      <td>0.899715</td>
      <td>0.855179</td>
      <td>0.983965</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>21</td>
      <td>1.149544</td>
      <td>0.899467</td>
      <td>0.841945</td>
      <td>0.987020</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>22</td>
      <td>1.105447</td>
      <td>0.882063</td>
      <td>0.854670</td>
      <td>0.982947</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>23</td>
      <td>1.113523</td>
      <td>0.888160</td>
      <td>0.857979</td>
      <td>0.983965</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>24</td>
      <td>1.131376</td>
      <td>0.892977</td>
      <td>0.845762</td>
      <td>0.983965</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>25</td>
      <td>1.073949</td>
      <td>0.896759</td>
      <td>0.847289</td>
      <td>0.985238</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>26</td>
      <td>1.076934</td>
      <td>0.872133</td>
      <td>0.860524</td>
      <td>0.984474</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>27</td>
      <td>1.063855</td>
      <td>0.886436</td>
      <td>0.851616</td>
      <td>0.984474</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>28</td>
      <td>1.060609</td>
      <td>0.883695</td>
      <td>0.858488</td>
      <td>0.983711</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>29</td>
      <td>1.053648</td>
      <td>0.879680</td>
      <td>0.856707</td>
      <td>0.981166</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>30</td>
      <td>1.031633</td>
      <td>0.853932</td>
      <td>0.868160</td>
      <td>0.985747</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>31</td>
      <td>1.031365</td>
      <td>0.864243</td>
      <td>0.857979</td>
      <td>0.985238</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>32</td>
      <td>0.990055</td>
      <td>0.857589</td>
      <td>0.863578</td>
      <td>0.983456</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>33</td>
      <td>1.005282</td>
      <td>0.866295</td>
      <td>0.863324</td>
      <td>0.982438</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>34</td>
      <td>0.995113</td>
      <td>0.868444</td>
      <td>0.855434</td>
      <td>0.985238</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>35</td>
      <td>0.988556</td>
      <td>0.872901</td>
      <td>0.858234</td>
      <td>0.984474</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>36</td>
      <td>0.977382</td>
      <td>0.861327</td>
      <td>0.868414</td>
      <td>0.982438</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>37</td>
      <td>0.980121</td>
      <td>0.855481</td>
      <td>0.866378</td>
      <td>0.982693</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>38</td>
      <td>1.002438</td>
      <td>0.845855</td>
      <td>0.872741</td>
      <td>0.983711</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>39</td>
      <td>0.982623</td>
      <td>0.861999</td>
      <td>0.868923</td>
      <td>0.981675</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>40</td>
      <td>0.959541</td>
      <td>0.848347</td>
      <td>0.871978</td>
      <td>0.983456</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>41</td>
      <td>0.958995</td>
      <td>0.847662</td>
      <td>0.874777</td>
      <td>0.982693</td>
      <td>03:04</td>
    </tr>
    <tr>
      <td>42</td>
      <td>0.950558</td>
      <td>0.843527</td>
      <td>0.877832</td>
      <td>0.982947</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>43</td>
      <td>0.925727</td>
      <td>0.826190</td>
      <td>0.877577</td>
      <td>0.986256</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>44</td>
      <td>0.938548</td>
      <td>0.851881</td>
      <td>0.873505</td>
      <td>0.982693</td>
      <td>03:07</td>
    </tr>
    <tr>
      <td>45</td>
      <td>0.925100</td>
      <td>0.838426</td>
      <td>0.876050</td>
      <td>0.981929</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>46</td>
      <td>0.924157</td>
      <td>0.836677</td>
      <td>0.872741</td>
      <td>0.982184</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>47</td>
      <td>0.943378</td>
      <td>0.830940</td>
      <td>0.881395</td>
      <td>0.980911</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>48</td>
      <td>0.921866</td>
      <td>0.851993</td>
      <td>0.874777</td>
      <td>0.980148</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>49</td>
      <td>0.917461</td>
      <td>0.818616</td>
      <td>0.883685</td>
      <td>0.983965</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>50</td>
      <td>0.887434</td>
      <td>0.824235</td>
      <td>0.883176</td>
      <td>0.981166</td>
      <td>03:07</td>
    </tr>
    <tr>
      <td>51</td>
      <td>0.885098</td>
      <td>0.822186</td>
      <td>0.885722</td>
      <td>0.981929</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>52</td>
      <td>0.876952</td>
      <td>0.821415</td>
      <td>0.882667</td>
      <td>0.980657</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>53</td>
      <td>0.875015</td>
      <td>0.808071</td>
      <td>0.885722</td>
      <td>0.982184</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>54</td>
      <td>0.888735</td>
      <td>0.815168</td>
      <td>0.885976</td>
      <td>0.983711</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>55</td>
      <td>0.865950</td>
      <td>0.799351</td>
      <td>0.887758</td>
      <td>0.984729</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>56</td>
      <td>0.869351</td>
      <td>0.809609</td>
      <td>0.885213</td>
      <td>0.980657</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>57</td>
      <td>0.847087</td>
      <td>0.815200</td>
      <td>0.880122</td>
      <td>0.983456</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>58</td>
      <td>0.846942</td>
      <td>0.794489</td>
      <td>0.892084</td>
      <td>0.983711</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>59</td>
      <td>0.842332</td>
      <td>0.799662</td>
      <td>0.889285</td>
      <td>0.985492</td>
      <td>03:07</td>
    </tr>
    <tr>
      <td>60</td>
      <td>0.848660</td>
      <td>0.802471</td>
      <td>0.887249</td>
      <td>0.980911</td>
      <td>03:07</td>
    </tr>
    <tr>
      <td>61</td>
      <td>0.845142</td>
      <td>0.785821</td>
      <td>0.893103</td>
      <td>0.982438</td>
      <td>03:07</td>
    </tr>
    <tr>
      <td>62</td>
      <td>0.829818</td>
      <td>0.784143</td>
      <td>0.894884</td>
      <td>0.988292</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>63</td>
      <td>0.837647</td>
      <td>0.788350</td>
      <td>0.894121</td>
      <td>0.983456</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>64</td>
      <td>0.821796</td>
      <td>0.779283</td>
      <td>0.895648</td>
      <td>0.984474</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>65</td>
      <td>0.821153</td>
      <td>0.781043</td>
      <td>0.893612</td>
      <td>0.983202</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>66</td>
      <td>0.813787</td>
      <td>0.769775</td>
      <td>0.896666</td>
      <td>0.983965</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>67</td>
      <td>0.818722</td>
      <td>0.772858</td>
      <td>0.897938</td>
      <td>0.985492</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>68</td>
      <td>0.839745</td>
      <td>0.768025</td>
      <td>0.899466</td>
      <td>0.985492</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>69</td>
      <td>0.801597</td>
      <td>0.768213</td>
      <td>0.901502</td>
      <td>0.987020</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>70</td>
      <td>0.816737</td>
      <td>0.764868</td>
      <td>0.900229</td>
      <td>0.984220</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>71</td>
      <td>0.818627</td>
      <td>0.765762</td>
      <td>0.901756</td>
      <td>0.986002</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>72</td>
      <td>0.814474</td>
      <td>0.764283</td>
      <td>0.905065</td>
      <td>0.986511</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>73</td>
      <td>0.823706</td>
      <td>0.763309</td>
      <td>0.902265</td>
      <td>0.986765</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>74</td>
      <td>0.795339</td>
      <td>0.760196</td>
      <td>0.902520</td>
      <td>0.987274</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>75</td>
      <td>0.842511</td>
      <td>0.760299</td>
      <td>0.905065</td>
      <td>0.986002</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>76</td>
      <td>0.823864</td>
      <td>0.762213</td>
      <td>0.904047</td>
      <td>0.985238</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>77</td>
      <td>0.823834</td>
      <td>0.761231</td>
      <td>0.904810</td>
      <td>0.985747</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>78</td>
      <td>0.807451</td>
      <td>0.762018</td>
      <td>0.903029</td>
      <td>0.984983</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>79</td>
      <td>0.795452</td>
      <td>0.759688</td>
      <td>0.903283</td>
      <td>0.986256</td>
      <td>03:05</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">recorder</span><span class="o">.</span><span class="n">plot_losses</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">get_learn</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span><span class="n">bs</span><span class="o">=</span><span class="n">bs</span><span class="p">,</span> <span class="n">mixup</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_fc</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">moms</span><span class="p">,</span><span class="n">start_pct</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>data path   /notebooks/data/imagewoof2
Learn path /notebooks/data/imagewoof2
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>top_k_accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.027628</td>
      <td>1.859925</td>
      <td>0.373886</td>
      <td>0.865106</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.862299</td>
      <td>1.682527</td>
      <td>0.493001</td>
      <td>0.899211</td>
      <td>03:07</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.733764</td>
      <td>1.446899</td>
      <td>0.584118</td>
      <td>0.941970</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.629644</td>
      <td>1.424300</td>
      <td>0.596589</td>
      <td>0.941715</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.568586</td>
      <td>1.263322</td>
      <td>0.678799</td>
      <td>0.957241</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>5</td>
      <td>1.476403</td>
      <td>1.223294</td>
      <td>0.701196</td>
      <td>0.965131</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>6</td>
      <td>1.469095</td>
      <td>1.145937</td>
      <td>0.743446</td>
      <td>0.969967</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>7</td>
      <td>1.392344</td>
      <td>1.078633</td>
      <td>0.768389</td>
      <td>0.972003</td>
      <td>03:07</td>
    </tr>
    <tr>
      <td>8</td>
      <td>1.380457</td>
      <td>1.069275</td>
      <td>0.783915</td>
      <td>0.972258</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>9</td>
      <td>1.348678</td>
      <td>1.072524</td>
      <td>0.774752</td>
      <td>0.974039</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>10</td>
      <td>1.317758</td>
      <td>1.021413</td>
      <td>0.795622</td>
      <td>0.980911</td>
      <td>03:07</td>
    </tr>
    <tr>
      <td>11</td>
      <td>1.304554</td>
      <td>1.016335</td>
      <td>0.806567</td>
      <td>0.981420</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>12</td>
      <td>1.250695</td>
      <td>0.966441</td>
      <td>0.821074</td>
      <td>0.978366</td>
      <td>03:07</td>
    </tr>
    <tr>
      <td>13</td>
      <td>1.235469</td>
      <td>0.954154</td>
      <td>0.822601</td>
      <td>0.977093</td>
      <td>03:08</td>
    </tr>
    <tr>
      <td>14</td>
      <td>1.246985</td>
      <td>0.960262</td>
      <td>0.821583</td>
      <td>0.979639</td>
      <td>03:08</td>
    </tr>
    <tr>
      <td>15</td>
      <td>1.223232</td>
      <td>0.944146</td>
      <td>0.824637</td>
      <td>0.983711</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>16</td>
      <td>1.206830</td>
      <td>0.924437</td>
      <td>0.836854</td>
      <td>0.982947</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>17</td>
      <td>1.180488</td>
      <td>0.925621</td>
      <td>0.838636</td>
      <td>0.981929</td>
      <td>03:08</td>
    </tr>
    <tr>
      <td>18</td>
      <td>1.137694</td>
      <td>0.922121</td>
      <td>0.836091</td>
      <td>0.983965</td>
      <td>03:08</td>
    </tr>
    <tr>
      <td>19</td>
      <td>1.170522</td>
      <td>0.916706</td>
      <td>0.838636</td>
      <td>0.981166</td>
      <td>03:07</td>
    </tr>
    <tr>
      <td>20</td>
      <td>1.157238</td>
      <td>0.892751</td>
      <td>0.854416</td>
      <td>0.983456</td>
      <td>03:07</td>
    </tr>
    <tr>
      <td>21</td>
      <td>1.153270</td>
      <td>0.899329</td>
      <td>0.849326</td>
      <td>0.983456</td>
      <td>03:09</td>
    </tr>
    <tr>
      <td>22</td>
      <td>1.135701</td>
      <td>0.886371</td>
      <td>0.856961</td>
      <td>0.982438</td>
      <td>03:07</td>
    </tr>
    <tr>
      <td>23</td>
      <td>1.101307</td>
      <td>0.891286</td>
      <td>0.854416</td>
      <td>0.982693</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>24</td>
      <td>1.103613</td>
      <td>0.904657</td>
      <td>0.845762</td>
      <td>0.984474</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>25</td>
      <td>1.092274</td>
      <td>0.888487</td>
      <td>0.849835</td>
      <td>0.978621</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>26</td>
      <td>1.058418</td>
      <td>0.903690</td>
      <td>0.843726</td>
      <td>0.983965</td>
      <td>03:07</td>
    </tr>
    <tr>
      <td>27</td>
      <td>1.076014</td>
      <td>0.878089</td>
      <td>0.857216</td>
      <td>0.983711</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>28</td>
      <td>1.051583</td>
      <td>0.868412</td>
      <td>0.856961</td>
      <td>0.984729</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>29</td>
      <td>1.027389</td>
      <td>0.884256</td>
      <td>0.852889</td>
      <td>0.987020</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>30</td>
      <td>1.067979</td>
      <td>0.878148</td>
      <td>0.858234</td>
      <td>0.986256</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>31</td>
      <td>1.052846</td>
      <td>0.886793</td>
      <td>0.855688</td>
      <td>0.983456</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>32</td>
      <td>1.042058</td>
      <td>0.890586</td>
      <td>0.849835</td>
      <td>0.982947</td>
      <td>03:07</td>
    </tr>
    <tr>
      <td>33</td>
      <td>1.016487</td>
      <td>0.846557</td>
      <td>0.874268</td>
      <td>0.986511</td>
      <td>03:07</td>
    </tr>
    <tr>
      <td>34</td>
      <td>0.985045</td>
      <td>0.857292</td>
      <td>0.863069</td>
      <td>0.987020</td>
      <td>03:07</td>
    </tr>
    <tr>
      <td>35</td>
      <td>1.012745</td>
      <td>0.864541</td>
      <td>0.863833</td>
      <td>0.986511</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>36</td>
      <td>1.008493</td>
      <td>0.851143</td>
      <td>0.871469</td>
      <td>0.988038</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>37</td>
      <td>0.974745</td>
      <td>0.858365</td>
      <td>0.864597</td>
      <td>0.983456</td>
      <td>03:07</td>
    </tr>
    <tr>
      <td>38</td>
      <td>0.990010</td>
      <td>0.871374</td>
      <td>0.857979</td>
      <td>0.982693</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>39</td>
      <td>0.974906</td>
      <td>0.842949</td>
      <td>0.869432</td>
      <td>0.981675</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>40</td>
      <td>0.986683</td>
      <td>0.854137</td>
      <td>0.865106</td>
      <td>0.985238</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>41</td>
      <td>0.941845</td>
      <td>0.830495</td>
      <td>0.874523</td>
      <td>0.988038</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>42</td>
      <td>0.955444</td>
      <td>0.855365</td>
      <td>0.862560</td>
      <td>0.981675</td>
      <td>03:04</td>
    </tr>
    <tr>
      <td>43</td>
      <td>0.935474</td>
      <td>0.851113</td>
      <td>0.868669</td>
      <td>0.982693</td>
      <td>03:04</td>
    </tr>
    <tr>
      <td>44</td>
      <td>0.964045</td>
      <td>0.863258</td>
      <td>0.866124</td>
      <td>0.981166</td>
      <td>03:07</td>
    </tr>
    <tr>
      <td>45</td>
      <td>0.922961</td>
      <td>0.828802</td>
      <td>0.877068</td>
      <td>0.982947</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>46</td>
      <td>0.945687</td>
      <td>0.862053</td>
      <td>0.869687</td>
      <td>0.980402</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>47</td>
      <td>0.945784</td>
      <td>0.830175</td>
      <td>0.878341</td>
      <td>0.984220</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>48</td>
      <td>0.889051</td>
      <td>0.817350</td>
      <td>0.887503</td>
      <td>0.983965</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>49</td>
      <td>0.901238</td>
      <td>0.819228</td>
      <td>0.880122</td>
      <td>0.984729</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>50</td>
      <td>0.904201</td>
      <td>0.816557</td>
      <td>0.882158</td>
      <td>0.984474</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>51</td>
      <td>0.881207</td>
      <td>0.807879</td>
      <td>0.880886</td>
      <td>0.984474</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>52</td>
      <td>0.889812</td>
      <td>0.800099</td>
      <td>0.887503</td>
      <td>0.984983</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>53</td>
      <td>0.903266</td>
      <td>0.789190</td>
      <td>0.894884</td>
      <td>0.986511</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>54</td>
      <td>0.875784</td>
      <td>0.794799</td>
      <td>0.888776</td>
      <td>0.983711</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>55</td>
      <td>0.873492</td>
      <td>0.796342</td>
      <td>0.890812</td>
      <td>0.984220</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>56</td>
      <td>0.852909</td>
      <td>0.789638</td>
      <td>0.892594</td>
      <td>0.983965</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>57</td>
      <td>0.858740</td>
      <td>0.784943</td>
      <td>0.898447</td>
      <td>0.985238</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>58</td>
      <td>0.868014</td>
      <td>0.781907</td>
      <td>0.895902</td>
      <td>0.983965</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>59</td>
      <td>0.846743</td>
      <td>0.794686</td>
      <td>0.892848</td>
      <td>0.984474</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>60</td>
      <td>0.858150</td>
      <td>0.786228</td>
      <td>0.891066</td>
      <td>0.985492</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>61</td>
      <td>0.839496</td>
      <td>0.786532</td>
      <td>0.901502</td>
      <td>0.983965</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>62</td>
      <td>0.851411</td>
      <td>0.777756</td>
      <td>0.897684</td>
      <td>0.985747</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>63</td>
      <td>0.820261</td>
      <td>0.776664</td>
      <td>0.898193</td>
      <td>0.982947</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>64</td>
      <td>0.818670</td>
      <td>0.775023</td>
      <td>0.905065</td>
      <td>0.985492</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>65</td>
      <td>0.821060</td>
      <td>0.764870</td>
      <td>0.905828</td>
      <td>0.983965</td>
      <td>03:04</td>
    </tr>
    <tr>
      <td>66</td>
      <td>0.821678</td>
      <td>0.768143</td>
      <td>0.903029</td>
      <td>0.983456</td>
      <td>03:04</td>
    </tr>
    <tr>
      <td>67</td>
      <td>0.812797</td>
      <td>0.766945</td>
      <td>0.904047</td>
      <td>0.983202</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>68</td>
      <td>0.820988</td>
      <td>0.767220</td>
      <td>0.904556</td>
      <td>0.984983</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>69</td>
      <td>0.831105</td>
      <td>0.763819</td>
      <td>0.906847</td>
      <td>0.985238</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>70</td>
      <td>0.832030</td>
      <td>0.761384</td>
      <td>0.906083</td>
      <td>0.986511</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>71</td>
      <td>0.777143</td>
      <td>0.760302</td>
      <td>0.910410</td>
      <td>0.985238</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>72</td>
      <td>0.817198</td>
      <td>0.758083</td>
      <td>0.909392</td>
      <td>0.984983</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>73</td>
      <td>0.821925</td>
      <td>0.758280</td>
      <td>0.906847</td>
      <td>0.986511</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>74</td>
      <td>0.824583</td>
      <td>0.754703</td>
      <td>0.908374</td>
      <td>0.986002</td>
      <td>03:05</td>
    </tr>
    <tr>
      <td>75</td>
      <td>0.825455</td>
      <td>0.753499</td>
      <td>0.910410</td>
      <td>0.986256</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>76</td>
      <td>0.798771</td>
      <td>0.753515</td>
      <td>0.909392</td>
      <td>0.986256</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>77</td>
      <td>0.810271</td>
      <td>0.754329</td>
      <td>0.910155</td>
      <td>0.985747</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>78</td>
      <td>0.795172</td>
      <td>0.752328</td>
      <td>0.910919</td>
      <td>0.986256</td>
      <td>03:06</td>
    </tr>
    <tr>
      <td>79</td>
      <td>0.797717</td>
      <td>0.754438</td>
      <td>0.909392</td>
      <td>0.985747</td>
      <td>03:06</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">recorder</span><span class="o">.</span><span class="n">plot_losses</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd3hUVfrA8e+bkBAgoYXQwQBSpAQIEaRIEUSKim0V7FhY2+qKu/6wd2XVdV3Xyqq47iquXRekqSii0oXQe4BQQygJpJByfn+cm8lMMpOEMJNJeT/PM09mzj33zpmrzDunizEGpZRSqqiQYBdAKaVU5aQBQimllFcaIJRSSnmlAUIppZRXGiCUUkp5VSvYBfCnJk2amNjY2GAXQymlqowVK1YcMsbEeDtWrQJEbGwsy5cvD3YxlFKqyhCRnb6OaROTUkoprzRAKKWU8koDhFJKKa+qVR+EUqp6yMnJITk5maysrGAXpdqIiIigdevWhIWFlfkcDRBKqUonOTmZqKgoYmNjEZFgF6fKM8aQmppKcnIy7dq1K/N52sSklKp0srKyiI6O1uDgJyJCdHT0KdfINEAopSolDQ7+VZ77GbAAISJtRGSBiGwQkXUico+XPENF5JiIrHIej7odGyUim0Rkq4hMCVQ5AVbtPsraPccC+RZKKVXlBLIPIhe4zxizUkSigBUiMt8Ys75Ivp+MMRe6J4hIKPAacD6QDCwTka+9nOsXl7z2MwBJU8cG4vJKqSomNTWV4cOHA7B//35CQ0OJibGTjZcuXUp4eHip15g4cSJTpkyhc+fOAS1rIAUsQBhj9gH7nOfpIrIBaAWU5Uu+L7DVGLMdQEQ+AsaV8VyllDot0dHRrFq1CoDHH3+cyMhI/vSnP3nkMcZgjCEkxHtDzPTp0wNezkCrkD4IEYkFegNLvBzuLyKrRWS2iHRz0loBu93yJDtp3q49SUSWi8jylJQUP5ZaKaU8bd26le7du3PbbbcRHx/Pvn37mDRpEgkJCXTr1o0nn3zSlXfQoEGsWrWK3NxcGjZsyJQpU+jZsyf9+/fn4MGDQfwUZRfwYa4iEgl8BvzRGJNW5PBK4AxjzHERGQN8CXQEvPWmeN0b1RgzDZgGkJCQoPunKlXNPPG/dazfW/Sr4/R0bVmfxy7qVnpGL9avX8/06dN58803AZg6dSqNGzcmNzeXYcOGccUVV9C1a1ePc44dO8aQIUOYOnUqkydP5t1332XKlIB2rfpFQGsQIhKGDQ4fGGM+L3rcGJNmjDnuPP8GCBORJtgaQxu3rK2BvYEsq1JKlUWHDh04++yzXa9nzJhBfHw88fHxbNiwgfXri7eE16lTh9GjRwPQp08fkpKSKqq4pyVgNQixY6reATYYY17ykac5cMAYY0SkLzZgpQJHgY4i0g7YA4wHrg5UWZVSlVd5f+kHSr169VzPt2zZwt///neWLl1Kw4YNufbaa73ONXDv1A4NDSU3N7dCynq6AlmDGAhcB5znNox1jIjcJiK3OXmuANaKyGrgFWC8sXKBu4C5wAbgY2PMugCWVSmlTllaWhpRUVHUr1+fffv2MXfu3GAXya8COYppEd77EtzzvAq86uPYN8A3ASiaUkr5RXx8PF27dqV79+60b9+egQMHBrtIfiXGVJ9+3YSEBFOeDYNip8wCdB6EUpXFhg0bOOuss4JdjGrH230VkRXGmARv+XWpDaWUUl5pgHCTn199alNKKXW6NEC4yatGzW1KKXW6NEC4ydMahFJKuWiAcHM0IyfYRVBKqUpDA4SbVbuPBLsISilVaWiAcHMgLTvYRVBKVQJDhw4tNunt5Zdf5o477vB5TmRkJAB79+7liiuu8Hnd0obiv/zyy2RkZLhejxkzhqNHj5a16H6lAcLN/jTdIF0pBRMmTOCjjz7ySPvoo4+YMGFCqee2bNmSTz/9tNzvXTRAfPPNNzRs2LDc1zsdGiDcHDimAUIpBVdccQUzZ84kO9u2KiQlJbF371569erF8OHDiY+Pp0ePHnz11VfFzk1KSqJ79+4AZGZmMn78eOLi4rjqqqvIzMx05bv99ttdy4Q/9thjALzyyivs3buXYcOGMWzYMABiY2M5dOgQAC+99BLdu3ene/fuvPzyy673O+uss7j11lvp1q0bI0eO9Hif0xHw5b6rkn0aIJSqfGZPgf1r/HvN5j1g9FSfh6Ojo+nbty9z5sxh3LhxfPTRR1x11VXUqVOHL774gvr163Po0CHOOeccLr74Yp/7Pb/xxhvUrVuXxMREEhMTiY+Pdx175plnaNy4MXl5eQwfPpzExETuvvtuXnrpJRYsWECTJk08rrVixQqmT5/OkiVLMMbQr18/hgwZQqNGjdiyZQszZszgn//8J1deeSWfffYZ11577WnfJq1BuDmgTUxKKYd7M1NB85IxhgcffJC4uDhGjBjBnj17OHDggM9rLFy40PVFHRcXR1xcnOvYxx9/THx8PL1792bdunVelwl3t2jRIi699FLq1atHZGQkl112GT/99BMA7dq1o1evXoB/lxPXGoQb7YNQqhIq4Zd+IF1yySVMnjyZlStXkpmZSXx8PO+99x4pKSmsWLGCsLAwYmNjvS7v7c5b7WLHjh28+OKLLFu2jEaNGnHjjTeWep2S1s2rXbu263loaKjfmpi0BuEm42ResIuglKokIiMjGTp0KDfddJOrc/rYsWM0bdqUsLAwFixYwM6dO0u8xuDBg/nggw8AWLt2LYmJiYBdJrxevXo0aNCAAwcOMHv2bNc5UVFRpKene73Wl19+SUZGBidOnOCLL77g3HPP9dfH9UprEEop5cOECRO47LLLXE1N11xzDRdddBEJCQn06tWLLl26lHj+7bffzsSJE4mLi6NXr1707dsXgJ49e9K7d2+6detWbJnwSZMmMXr0aFq0aMGCBQtc6fHx8dx4442ua9xyyy307t07oLvT6XLfFC73Dbrkt1KVgS73HRi63LdSSim/0AChlFLKKw0QSqlKqTo1f1cG5bmfAQsQItJGRBaIyAYRWSci93jJc42IJDqPX0Skp9uxJBFZIyKrROTUOxaUUlVWREQEqampGiT8xBhDamoqERERp3ReIEcx5QL3GWNWikgUsEJE5htj3GeD7ACGGGOOiMhoYBrQz+34MGPMoQCWUSlVCbVu3Zrk5GRSUlKCXZRqIyIigtatW5/SOQELEMaYfcA+53m6iGwAWgHr3fL84nbKYuDUSq+UqpbCwsJo165dsItR41VIH4SIxAK9gSUlZLsZmO322gDzRGSFiEwq4dqTRGS5iCwv76+NTs0iy3WeUkpVZwEPECISCXwG/NEYk+YjzzBsgPg/t+SBxph4YDRwp4gM9nauMWaaMSbBGJMQExNTrjLOu3dIuc5TSqnqLKABQkTCsMHhA2PM5z7yxAFvA+OMMakF6caYvc7fg8AXQN9AlrXA8ezcingbpZSq9AI5ikmAd4ANxpiXfORpC3wOXGeM2eyWXs/p2EZE6gEjgbWBKqu7fB01oZRSQGBHMQ0ErgPWiMgqJ+1BoC2AMeZN4FEgGnjdWfEw15ny3Qz4wkmrBXxojJkTwLK65OZpgFBKKQjsKKZFgPddNArz3ALc4iV9O9Cz+BmBc/+ozjw/ZxO5efkV+bZKKVVp6Uxqx4tzNwHw3caDQS6JUkpVDhogHPlOy9Jf520uOaNSStUQGiCKOHQ8m52pJ4JdDKWUCjoNEI5nL+3hej7khR+CVxCllKokNEA4rkzQVT6UUsqdBghHrVC9FUop5U6/FZVSSnmlAcLNt5O9LveklFI1kgYIN2c2jQKgbeO6QS6JUkoFnwYIL3Ydzgh2EZRSKugCuRZTldSvXWN0vT6llNIaRDH1atciKzcv2MVQSqmg0xpEERv3pbH3WFawi6GUUkGnNYgiNDgopZSlAcKHIydOBrsISikVVBogfEjP0q1HlVI1mwYIH979eUewi6CUUkGlAaKI6/ufAcB7vyTx1o/bglwapZQKHg0QRdwwINb1/LnZG4NXEKWUCrKABQgRaSMiC0Rkg4isE5F7vOQREXlFRLaKSKKIxLsdu0FEtjiPGwJVzqLqhIV6vDY6a04pVUMFch5ELnCfMWaliEQBK0RkvjFmvVue0UBH59EPeAPoJyKNgceABMA4535tjDkSwPICdqKcu+zcfCKKBA2llKoJAlaDMMbsM8asdJ6nAxuAVkWyjQPeN9ZioKGItAAuAOYbYw47QWE+MCpQZXXXoE6Yx+sjGTrcVSlVM1VIH4SIxAK9gSVFDrUCdru9TnbSfKV7u/YkEVkuIstTUlL8VWSXlPRsv19TKaWqgoAHCBGJBD4D/miMSSt62MsppoT04onGTDPGJBhjEmJiYk6vsA73fggNEEqpmiqgAUJEwrDB4QNjzOdesiQDbdxetwb2lpBeIX6ecp7ruQYIpVRNFchRTAK8A2wwxrzkI9vXwPXOaKZzgGPGmH3AXGCkiDQSkUbASCetQjSuF+56PuXzNeTn60gmpVTNE8hRTAOB64A1IrLKSXsQaAtgjHkT+AYYA2wFMoCJzrHDIvIUsMw570ljzOEAlrVE+9KyaNWwTrDeXimlgiJgAcIYswjvfQnueQxwp49j7wLvBqBoZXJBt2bMXXcAgLw8rUEopWoenUntw+XxrV3PE/ccDWJJlFIqODRA+NDSrUmpUd3wEnIqpVT1pAHCh+6tGrien8zND2JJlFIqODRAlKBXm4YAnDipe0MopWoeDRAleO0au3ZgRnZekEuilFIVTwNECeqF2xnVWoNQStVEGiBKUDfcjgJ+/QfdOEgpVfNogChBeC17e3S5DaVUTaQBwpciGwWt3XMsSAVRSqng0ABR1MGN8FI32DLfI/n6d5cGqUBKKRUcGiCKqt8S0pJh/2qP5MMndOMgpVTNogGiqIj60Kgd7EsMdkmUUiqoNEB40yIO9tsA8dntA4JcGKWUCg4NEN606AlHkiDrmGs2tVJK1TQaILxp3tP+3b+G0JDCFctjp8xi3rr9QSqUUkpVLA0Q3rSIs3+99ENM+veKCi6MUkoFhwYIbyKbQmRzVz+EUkrVRBogfGkRpyOZlFI1mgYIX5rHQcpGyMkKdkmUUiooAhYgRORdETkoImt9HP+ziKxyHmtFJE9EGjvHkkRkjXNseaDKWKIWcWDy4OB6fj+4vcehdXt12Q2lVPUXyBrEe8AoXweNMS8YY3oZY3oBDwA/GmMOu2UZ5hxPCGAZfWvudFTvT+T+UV08Do19ZVEQCqSUUhUrYAHCGLMQOFxqRmsCMCNQZSmXRrFQuwHsS/QY6qqUUjVF0PsgRKQutqbxmVuyAeaJyAoRmVTK+ZNEZLmILE9JSfFnwaB5D9dIpnn3DmbEWc1ch3PydJ9qpVT1FvQAAVwE/FykeWmgMSYeGA3cKSKDfZ1sjJlmjEkwxiTExMT4t2Qt4uDAOsjPo1OzKL7dcMB1qONDs/37XkopVclUhgAxniLNS8aYvc7fg8AXQN8glMv2Q+RkQOpWAO4Z3jEoxVBKqWAIaoAQkQbAEOArt7R6IhJV8BwYCXgdCRVwrhnVdunvogEiL98UPUMppaqNQA5znQH8CnQWkWQRuVlEbhOR29yyXQrMM8accEtrBiwSkdXAUmCWMWZOoMpZoiadILS2K0CEFOmsTnh6vrezlFKqWqhVlkwi0gFINsZki8hQIA543xhz1Nc5xpgJpV3XGPMedjise9p2oGdZyhVwoWHQrKvPJTeOZORUcIGUUqrilLUG8RmQJyJnAu8A7YAPA1aqyqS5s+SGs0f1sodGeBw2RpuZlFLVU1kDRL4xJhfbJPSyMeZeoEXgilWJtIiDrKNwLBmAmKjaHodz8jRAKKWqp7IGiBwRmQDcAMx00sICU6RKJsaZRZ26xZX08e/7u55PW7itokuklFIVoqwBYiLQH3jGGLNDRNoB/wlcsSqRxh3s39TCQNCjVQPX8xfnbeZkrk6aU0pVP2UKEMaY9caYu40xM0SkERBljJka4LJVDlHNIawuHN7uSqpdy/O2/XvxzooulVJKBVyZAoSI/CAi9Z3VVlcD00XkpcAWrZIQgcbtPWoQISHCvHsLJ3c/NXM9ubr0hlKqmilrE1MDY0wacBkw3RjTBxhRyjnVR+P2cNizr6Fj00iP132f/a4iS6SUUgFX1gBRS0RaAFdS2Eldc0R3gCNJkJfrShLxnDR3+MRJHfKqlKpWyhogngTmAtuMMctEpD2wpZRzqo/GHSA/F47t9kh+ZUJvj9crd/mcN6iUUlVOWTupPzHGxBljbndebzfGXB7YolUi0c5IpiLNTBfFeU4Fmbd+f0WVSCmlAq6sndStReQLZwvRAyLymYi0DnThKg3XUNftHslFm5ne+tHzuFJKVWVlbWKaDnwNtARaAf9z0mqGyKYQHlmsBuHN8L/+wIG0rAoolFJKBVZZA0SMMWa6MSbXebwH+Hl3nkrMy1DXAmN7eDYzbUs5wYCp31dUyZRSKmDKGiAOici1IhLqPK4FUgNZsEonuoPXGsRfryy+8KzuE6GUqg7KGiBuwg5x3Q/sA67ALr9RczRuD0d2Qp7nEt8RYaG8c0NCkAqllFKBU9ZRTLuMMRcbY2KMMU2NMZdgJ83VHI07gMmDo7uKHTqvS9NiabqIn1KqqjudHeUm+60UVUF08UX7CogIV/dr65H27DcbK6JUSikVMKcTIKT0LNVIY+9zIQo8c0n3CiyMUkoF3ukEiJrVE1uvCdSu77UGAbYWsfxhz+Wpnp+zkePZuV7zK6VUZVdigBCRdBFJ8/JIx86JKOncd52JdWt9HB8qIsdEZJXzeNTt2CgR2SQiW0VkSrk+mb8VDHUtYS5Ek0jP3eZe/2Eb3R+bG+iSKaVUQJQYIIwxUcaY+l4eUcaYWqVc+z1gVCl5fjLG9HIeTwKISCjwGjAa6ApMEJGuZfs4ARbdwWcNosCO58b4PJaVk0e+DoFVSlURp9PEVCJjzELgcDlO7QtsddZ7Ogl8BIzza+HKq3EHu2Bf7kmfWUSEN66J90hbt/cYefmGLo/M4Yn/rQt0KZVSyi8CFiDKqL+IrBaR2SLSzUlrBbgvm5rspHklIpNEZLmILE9JSQlkWW0NwuTbpb9LMLJbc4/XY19ZxPXvLgHgX7/q7nNKqaohmAFiJXCGMaYn8A/gSyfd2+gon+0yxphpxpgEY0xCTEyAV/9wjWQqeVG+0JDiH+HnrYUTz3UPa6VUVRC0AGGMSTPGHHeefwOEiUgTbI2hjVvW1sDeIBSxuMbt7d8yLNp344BYn8cSk3XfCKVU5Re0ACEizcVZL1tE+jplSQWWAR1FpJ2IhAPjsSvJBl/dxhDRoNSOaoDHL+7m81h4rWC37CmlVOlKG4lUbiIyAxgKNBGRZOAxIAzAGPMmdj2n20UkF8gExhu7Z2euiNyF3cEuFHjXGFM5enZFbDNTGWoQAGGhQk5e8daxp2dtIL5tI/5vVOdie0oopVRlEbAAYYyZUMrxV4FXfRz7BvgmEOU6bdEdYMdPkJ0OtaNKzLrw/mH0f6740t9Ldxxm6Y7DtI+px5UJbbycqZRSwadtHaeq8xg4fgDeGADbfywxa4sGdUo8fv+nidhKk1JKVT4aIE5V98vgpjkQEgbvXwwzJ0P28TKd2ueMRsXS3lqo25QqpSonDRDl0fYcuG0R9L8Llr8Ln0/ymXVk12au5zd4Gdn0w6aDgSihUkqdtoD1QVR74XXhgmcgJxMS/wv5eRASWizbtOsTOJiexY6UE7SPiSx2fPfhzIoorVJKnTKtQZyu1mfDyeNwaLPPLE2jIujXPpqYqNrFju05mklWTh4H07MYOPV75qzdH8jSKqVUmWkN4nS16mP/7lkBTc8q1yWG//VH9hy1NYkX5m5kVPfmpZyhlFKBpzWI0xV9pt0nYs+KMmV/9erenNuxiUdaQXAA2JZywq/FU0qp8tIAcbpCQqBl7zIHiAvjWvLvm/ux+enRJeZbuesI93z0G3m6PLhSKkg0QPhDqz5wYJ3tsC6jkpbbOJ6dy2Wv/8JXq/ayPKk8K6YrpdTp0wDhD636QH4u7F/jl8u570L35ao9frmmUkqdKg0Q/uDeUX0K3rquT6l5ZizdzYJNB3n1+y3lKZlSSpWbjmLyh/otIKrlKQeIC7qVbbTSxOnLAJg0uIOuBKuUqjD6beMvreJPOUAAPH95HAAz/zCo1LydHp7N+S/9yNo9x5i//gATpi12reX00vzN/LbryCm/v1JK+SLVabG4hIQEs3z58uC8+U8vwXdPwP077L4RZZSfbzh0PJum9SMwxjDxvWX8sKnsW6dufGoU4aEhtH/QLn6bNHXsKRddKVVzicgKY0yCt2Nag/CXgn6IvStP6bSQEKFp/QgARIT3JvY9pfPTs3I5lplzSucopVRZaB+Ev7TsBQjsWQlnjqiwtz37mW/p267sNRallCorrUH4S0QDaNKpXP0QRc2/dzC/PnBemfMv3aFzJZRS/qc1CH9q1Qe2zgdj7Pak5dSxWck71SmlVEXQGoQ/tYqHEylwbLdfLvfa1fGu51Mv6+GXayqlVFkFLECIyLsiclBE1vo4fo2IJDqPX0Skp9uxJBFZIyKrRCRIw5LKoZwT5nwZG9eCp8Z1A2B837ZMPr9TqefETpnlehzNOOlK37Q/naycPL+USylVMwSyBvEeMKqE4zuAIcaYOOApYFqR48OMMb18Db+qlJp1h9DasOZT28zkB9f1j3UNXb17eEe+vHNgmc/9dEUyq3Yf5bMVyVzw8kL+MOM3v5RJKVUzBKwPwhizUERiSzj+i9vLxUDrQJWlwtQKhyH3w/dPwY/Pw9D/8/tbdGle2D8xtHNMiXMmnp61weP1/PUH/F4epVT1VVn6IG4GZru9NsA8EVkhIr43fAZEZJKILBeR5SkpZZ9gFjDn3gdx4+GHZ21Nws8iwgq3NX3jmtLXcirqQFqWP4ujlKrGgh4gRGQYNkC4/9weaIyJB0YDd4rIYF/nG2OmGWMSjDEJMTExAS5tGYjAxa9A2wHw5R2we6nf3+LKBFvZigg79f98f/jwN/LzDf/6JYkVO3V4rFLKt4AuteE0Mc00xnT3cTwO+AIYbYzxuqmziDwOHDfGvFja+wV1qY2iTqTC28MhOx1+/yM0CEwLWs8n5p3WTOoHRndh4ZYUPrjlHD+WSilVVVTKpTZEpC3wOXCde3AQkXoiElXwHBgJeB0JVanVi4ZrPoHsNLtOU4AsfWg4v0w5j6/cOq/fvDa+hDM8PTd7Iz9vTSV2yiwOujU/GWN4+6ftHEzXJimlaqpADnOdAfwKdBaRZBG5WURuE5HbnCyPAtHA60WGszYDFonIamApMMsYMydQ5QyoJh2hx5WwegZkBKY5p3atUFo2rEPPNg35Zcp5fDTpHEZ1b1Gua/V99jt+2pKCMYbE5GM8PWsDfZ/5jpW6SqxSNZKu5hpo+9fAm4NgxOMw6N4Ke9uPl+/m/k8TSTijEct3nv4XvK4Sq1T1VCmbmGqM5j2g3WBY+k/Iq7hVV69MaEPS1LF8/Pv+FfaeSqnqRQNERTjnDkjbA+u/qvC3DgkRBneKYfrEs0/rOqt2H+X9X5N4ce4mFm05RG5evn8KqJSqtLSJqSLk58OrfaBOY7j1u6AVI3bKLL9dq3/7aKZPPBsR6Pyw7SLSZiilqh5tYgq2kBDodzvsWR6QeRFltfzhwn0q3L/Mtz075pSW8AD4dXsqXR6Z4woORWXn5vHezzt0/SelqjBd7rui9Loavn8aFr8ObU5t1zh/aRJZm2UPjSAs1C5F/v19Q9hzNJPQEKFXm4asfOR84p+af1rvcSwzh55PzKNR3TCOZOSwLeUEI7s149yOlWASo1LqlGgNoqLUjoQ+18P6r+HIzqAVIyaqNg3rhgPQPibS44u7cb3wYvlPZZnxtKwcXv9hKwBHMmyH/L8X7+S6d5ZSnZoylaopNEBUpH63Q0go/FTqpPBK45LercqcN+7xecxcvc/rse6PzeU3L/MpUo9nl7tsSqnA0gBRkRq0gvgbYNWHcCQp2KXx6qqENh6v3RcHLIs9RzO9pp84mcelrxcu4JuVk8fnK5Pp8/S3XgOHUir4NEBUtHMng4TCwheCXRKvpl7eg1WPns+jF3Zl41MlbedRPidz7fDYuCfmMfnj1QC8OG8TAPn5hl+3pfr9PZVS5aMBoqLVbwkJE2HVDDi8PdilKUZEaFg3nJsGtXPVHjY8OYr1T17AqG7NefbS4n0Sdw7rUObrd3p4NrFTZrkCBcDPW21Q+MucjUz452I+We6fLVuVUqdHA0QwDLoXQsNgYdXoi6gTHkrd8Fq8eV0fru7XlnM7NgHsooBJU8fy5wu6+OV93lpoA+afP00kdsosHvpijV+uq5QqHw0QwRDVHBJugtUfQeq2YJfmlL16dTz3j+rMyK7N/XZNb5P4Pliyi6dmrne9XrvnGJsPpPvtPZVSJdMAESwD/wih4fDt4wFb6TVQGtQJ446hZxISIq60lY+cz2+PnM8tg9p55P12ss+9nsrknUU7WL37KA9/uYYL/7GIkX9b6LEsuVIqcHSpjWD67kn46a+AQKt46DAcGraF4wfsIyMV4q+H9kODXNBTsz3lOOf99UfAztj25xIfBcqyrMdzszcwqltzerdt5Pf3V6q6KGmpDQ0QwWQMJC+Dbd/D1u/sUhzG6byNaODkAe5cbDu3q5C3ftzGwDOb0L1VAxZvT2XFziO8MHeTX9+jXngoJ07mcUWf1ny6Ipl7hnfk3vM7AfDbriOuYbXbnh3D3TN+47wuTbm8T2B29lOqqtIAUVVkHoWsoxDZDMLq2P6JNwZAuyFw9X/tftdVWFZOHhFhoXR+eDbZuYFZDTZp6lhy8vK56B+L2Ljf9lcse2gEZz/zLQD/ubkfWw6m0yEmkk7NomjeIAJjDMezc4mKCAPgtQVbiaxdixsGxAakjEpVJhogqrJfX4O5D8Klb0HP8cEujV8FoukJoFaIkJtf+P91k8hwDh0/6TXv/+4axJMz17Es6Qjf3zeE9jGRrnLp6rSqJtDVXKuyfrdBm3Ng9v2Qvj/YpfGrpKljXY9zOzbhzKaRHse3P9YTqdkAAB0jSURBVDvGY45FWfe0cA8OgM/gAHDRq4tYlmRncj83e6PHMV8/njYfSOf+T1fr+lKq2tMAUdmFhMK41yA3G/73R9tvUQ39++Z+fDt5iMfs7ZAQYeCZds5F1xb1Gda56WlvfFSSs2MbeXzp7z6cSU5ePou2HCJ2yiz2HbPLiIz820I+Xp7MJh1yq6q5gC73LSLvAhcCB40x3b0cF+DvwBggA7jRGLPSOXYD8LCT9WljzL8CWdZKrcmZcN4jMO8heKU3NOkE0WdCi57Q4wobRKqJiLBQj6aduNYNadkggkcv6grAsM5NmXX3IMa+ssjv7/3sNxtp1bCu6/XgFxYAEO2sctv/ue/58wWdXcfznJrKiexcQkSoE27/OxzPziVEoG64rqavqrZA/x/8HvAq8L6P46OBjs6jH/AG0E9EGgOPAQnYcTwrRORrY0zNXdXtnNsBA8nLbef1joWQmwnH98PAe4JduoCJrF2LXx4Y7pHWrWUD1/Mf/jSUyIhajHr5Jw75YWXYOz9cWSwt9URhE5X7SKx1e9Jo27guPR6fBxT2WXR/bK7Ha6WqqoAGCGPMQhGJLSHLOOB9Y+v1i0WkoYi0AIYC840xhwFEZD4wCpgRyPJWaiGhMOAPha/z8+GT6+0mRB1HQtOzgle2IGreIIKIsFCWPzyCBz5fw4ylu1zHJp/fiZfmb2bK6C5c0qsVzRtEAP7rHL//s0Tu/yzR5/HcvHxqhWorrqq6gl0HbgW4r8yW7KT5Si9GRCYBkwDatm0bmFJWRiEhMPZvsPMc+OL3cMt3dn2nGmLN4yPZmZrhsRz5c5f14Mlx3bjktZ/p1CyKu4d3ZOLAWNfw1Yr21aq97D2ayWs/bGVsj5aEhsCOQydYlnSEAR2i+fDWc4JSLqXKKtgBwtvAflNCevFEY6YB08AOc/Vf0aqAyBi48G/w8XV24b9hDwS7RBUmKiKM7q0aFEsPCw1h1t3neuSrKHuOZlK7VmGN4b5PVruef7Yy2SPvL9tSMcaQnZt/yntuKFVRgl3/TQbcd6hpDewtIV0V1fViiLvK7i+x97dgl6ZK+en+Ya7n9wzv6Hr++yHtSz23bnjxL/WBU78n4elvy/z+/122my6PzGF7ynHy8g35+QZjDBv3p5GTl897P+8gKyfP1RkOcM9Hv/HFb8klXFUp/wn4RDmnD2Kmj1FMY4G7sKOY+gGvGGP6Op3UK4B4J+tKoE9Bn4Qv1XKiXFlkHoHXB0BoLRhwN3S/HOo29syTdQzC6tk8Ndyq3UfZvD+dK89uw8G0LBrWDSe8Vgh7j2bSsmEdoOR+ikcv7MqTbqvMnq6pl/Vgyud2afP7R3Xm+TmbaF4/gv1uixIWdHgXlGvHc2PYdTiDM6LrufKczM3n2w0HGN29OVLFZ92rihO0mdQiMgPb4dwEOIAdmRQGYIx50xnm+iq2AzoDmGiMWe6cexPwoHOpZ4wx00t7vxobIAB2LYaZ98LB9RASZjuum5wJB9bDgXWQvhfqt4aBd0Pv6yC8bunXrME27U9n77FMmteP4EjGSc5pF83TszawM/UE79x4tkcAeeyirjzxP/8FDG8KlhDp+NBsAAZ0iOaXbancOCCWxy/uBsALczfy2oJt/OumvgzpFIMxhgNp2a7OeaW80aU2agpj4MBau8/Emk/tarAxXaBZN2jSEbZ+C7t+hbpN7LDZfr+H2lHBLnWVVBAgwkKFqZfFefQ3BMrqR0fS88l5Xo/FtW5AYvIxwDaRPTD6LJ79ZgPTFm7n67sGEte6YcDLp6omXWqjphCB5j3ggmdg8gZ4aD/cvgguewsG/wlumgMTZ0PL3vD9U/CPPrDqQztkVpXLuidGMa6X75V2WzaI4F839XW9/uz2/oSGlK/5x1dwAFzBAeCtH7ezavdRpjk79LkP/QXIOJnr5fyjxE6Zxd6jmeUqm6qetAZRUyUvh9n/Z5cYb9UHRjwBUS3s5Lscp+07qhlENoda4cEtayV0IjuX9KxcV/PN4OcXcPOgdlzf/wxEhNy8fD5ZkcyEvnbodWLyUTbsS+Oqs9uy9eBxRrz0Y4WV9Y1r4hndowUAHy/bzf2fJRarVRTUiO4Y2oH7R/lnC1lVNWgTk/IuPx/WfAzzH7Mzsn2pG203MmrSyT5iOkPsuVBHmy3Ka8/RTKYv2sHstfvZUwG/2kNDhHE9W/L5b3sAuKJPa178XU/X8YIA0a1lfY9hwgVS0rOJiaod8HKqiqcBQpUsOx022c5PakXYvSiMsUEjfT+k7YUjSXBoM6TZLxgim8Elr8OZI4JW7OrC14ipgpFLS3cc5sq3fvX7+xZc/3h2rmt5kGvPacvdwzuSnpXLnLX7uWNoB77bcJBb3l9O39jGfHxbfwBy8myzZJjOFK/ySgoQOuZR2Y7quCvLljc7Hfaugm/+DP+53C5HPuLxwqBydJd9tE6wab5kpcHaT2H1f6FeE7tHdxu3lVpPZsDqGXa3vX63Qbviv2qrI29btHZpUTiQ4MNb+3H1P5d4PbdVwzr84bwzXUNmS9PugVkYA4OcFXMB/rN4F/9ZvIv2MfXYnnKC3yW05oMlOwFYmmRHmee6jaba/uwYj73JVfWiNQhVPjmZ8O0TsOQN2+wU1QL2rbY74gHUbmBXmu19DbSMt/mP7LALDW6ZC2u/gJwTEHOWralkHrHNVufcAXtXwrJ3IPMwhEdCTgYMfRDOvc8uMXI68nIgfZ+tFdWKgJa9Tv9enKYfN6dww7tL+ffNfTm3YwzHs3M5lplDq4aFAXbP0Uw27E1jRNdmvPr9Fl6ctxmAcb1akptvOJmbz2tXx3M08yR9n/kOsGMWTvef933nd+Kv8ze7Xt817ExeXbDV9frmQe145MKup/cmKqi0iUkFztbv7I53tSLs8uMt4mzH9vqvYMPXkJsFdRrZAFAgrB70uBzib7Ad5CdPwMp/wS//sF/eCHQeAwPusqOyZt4Laz6BDufBZf+0NY6iMg7ba2Sn22G9zbpD4w62aSxpIez4CXYvsYHBfdWWy9+xgawKmbtuP7//9wqeuqQ7151zhscx97kS3mojgbDjuTGuiXn5+Yb2D34D2Pkho7o3Jzsnn9gm9Uq6hAoiDRAqODKPwrrPYc9KaHgGRLe3X9pNOnmfqJebbedqxHSB6MKd5DAGVrxnR12F17PBo+MIaD8MTh6327Ku+JetkUgomDx7nvvzqBZwxkB73fqt7OOnF2FfItz6PTT148idglFgYYGZoGaMYfnOIySc0cjrjOnYKbO49dx2PDS2K7l5+Vzz9hKW7ChxEYKAi4qoRXpWrquW5C4rJ4+/zd/MRT1butbX2n04g/p1woisXYujGSeJjtQO8kDRAKGqh32JsOgl2y+RdcwGgIJ2lB6/s7PEo8+0nekH1kHKRjv6KnawDQxFv0zT9sFb59oazq3fe580mJ8PqVthf6KtlfgKJMbAvlXw239sbSc/z9ZOOo/ynr+8juy0fTuRTb0fP5lR6iz5g2lZ9H32u2LpSx4cTj8v6YEwNq4FL1/Vi7DQEI9azo0DYjmQlsXstZ6j6v58QWduGtiO/WlZtHOrjTzw+RrSMnN47Zp4VPlogFDVS14uJC+DrfPtF/HZN9tAUB47foL3L4au4+AKZzWXgxtg4yzY+bOt/WQXTkKjTT/bNNbtEtustWc57FkB2xbYWey1IuCsi+HQJhvQRj4N/e8sDE7G2L6YqBbeO/Gz020ArNvEfqb6LQtrYokfQ/JSqNcUbpwFMZ08z038GL68Hc6+FS54ttT+ml+3pVIrVJg4fRmf3Nafs1rUB/y3X0agfHBLP9dWtAVl/fv4Xozr5XVHAFUKDRBKleSnl+C7J6DLhXYtq8N2BjLNekDrPtAqAZp3h6RFtikrdYtn81VobTs7Pe5Ku1BinYa2X+WL22w/TO/rIGEibPif7Zs5vB0at4dLp3mO3NqzEj69yQaQAiG1bFAxedC0qw1ky94BCbFBosmZNt+qD+HLO2zTWVoy9LoGLnrltBZndA8U304eTJ3wWgyc+n2Zzn1gdBeem72x3O9dFgv/PMy1LSzAlmdGEyrC37/bwlVnt3EtvFgWmSfzOJmXT4M6NWdPlQIaIJQqSX6+3VNj8xxoN9gGii5jIap58bzG2PWsNn1j+1Va9bFNT95mm+fnw4JnbF8H2KDSbjB0GAZL37Zf5Of+CQb/GZZOg28ft01HY1+y1ysYMoxAt0ttkAJbw3nvQrtB1I2zbOD63z3QfiiM/9B29v/wLJx1kW3mqlW+9vuU9GyWJR1mjDMLu0BB4EiaOpa3f9rO07M2ALD2iQtc8yl2PDeGvHzDhn3pXPSq//cPL4sOMfV47Zp4ujS3NaPx035l8fbDRNcLJ/XESb64YwC92zZi9e6jjHvtZ9dnKmCM4eetqSTENuLr1Xtp3agOAzoUDpC47p0l9I1tzB+Gd2TO2v307xDtNcAkHTrB0Bd/YNPTo6hdK5RVu4/StUV9wp29Q4wxLNxyiH7tGpe6N0jmyTzX3uf+ogFCqdLk59lO8kCscrvte9vf0Xl04TLsWWm20331h1CnsR3S2+VCuPgfxZdq9+bAOvjXRTZgZR6GM8+Hq/5T2DG++A2YMwXaDYHzn4AWvYr3wfjJi3M3MaFfW1o1rMOPm1OIa9WARvUKA2awm6zWPXEBqcdPetQ2Cjx3WQ8eKDJv5C+X92D22v38sCnF5zU3PjWKLo/MKZae+PhI8vMN176zhL/+rhdtG9flrEcL831yW39+96ad9FgwRPj/Pk3kv8vtBpof3tqPAR2asC3lOHPW7uf2IR1c80ye+2YDby3czu/6tOb5K+L8tqS7BgilKqv1X8EPU6HPROh766l9ie9fA+9fYvtFfje9eE3ht//AzMmQlw1Nu9k5KWeOsEOPs9PtQ0LsUip1G9t+j9pRfg8ku1IzOHEyl5O5+bz3SxJfOMt9FJU0daxrnar/3TWI13/YSuN64XywZJfX/NWBt4EBRYcnfzt5CG0a16Hzw3OK5fMHDRBKVVe52RAa7vtLPfMIrP0MfvvATkAsTf3Wthms3bl24mLDNqWfc4qSj2QQIsL2lBP88b+/cej4yRL36M7KyWPQXxZw6Hg2M/8wiO6tGnh8gW5/doxr7kV1UDc8lIyTeaXm++CWflzz9hLCQ0PY/Mzocr+fBgillO272Lfazk6vHWUfJt+OxspIhRMH7YispEX2NUCDNraG0vYc+2jW3a81DGMMmw6ku/oJymvO2v3c9p8VfipV1ZNwRiM+vX1Auc7VAKGUKrv8fDuaK2kR7F4Mu5bYHQnBBoyzLrKPFr3g8DZI2WSDz/H9dvTWyRN2PkZUM2d2fS87w75Oo9LfO+OwrfFkHoUz+tsRZKcw4TD5SAZ1w2sR/9T8EvO5b+l667nt2Hcsi5mJ+0o8Z1S35sxZV8Kqx0FW3iYnDRBKqfIzBo7thh0LYcNM2+mel+2ZR0LtCr+1IyGsrn0c220fBeo1tcN7G7eDRrE2f2RTqBdjA8PqD+2qwnknC88JrQ2tz7bzQUy+fYBdTqXdEDu8uAxDeXemniD1xEni2zZyPpJh37Es11BYYwztHvBspnr20h4M7tSEQX+xndtz/ziYC15e6Dq+4E9DXZP2Bj+/gF2HM1zHXr8mnoEdmrg2efrqzoGukVK92jTkyzsHejSTJU0dy8b9aYx6+acSP8dHk85h/LTFXo9pgCiFBgilKkB2OmyZb2eYR59ZuDSKt+G0J1LtDPP9iXahxsM77DyPNC8d1XWjoceV0Otq2/exa7GtxSQtsotASogNRPm5hXNFwqPsXJI6jewkxYLl6sPrOY9IOxw5dlCpNZEfN6fQqmEEu49kMrRTjNdRQl/8lszws5oRGV7LYxXbZUmHXaOTAGbceg79O0Qz7rWfOfuMRjx8YVe2pxzHAB1iIgG7btabP2xj0pD21K5lh65+tWoPWw8eZ+/RLJ65tLvHSKmCALDvWCb9n/Ocj9Ihph7f3Te0xM/nS9AChIiMAv4OhAJvG2OmFjn+N2CY87Iu0NQY09A5lgcUjD/bZYy5uLT30wChVBWRexJOpNh+j+MpdtZ37OCy71544pANHDsW2tns2cdth31ull05OOeEZ/6wunaeSKdRtsZy/IDzOGj7VAoCS0GQM8bWVkKcmlFkczsvJrKpE4w8g+G6vccY+4qd7/HIhV25aWCsX4ahHjqezZrkYwzrUnxplave+pUlOw67hsaWV1AChIiEApuB84FkYBkwwRiz3kf+PwC9jTE3Oa+PG2MiT+U9NUAopQDbj5JzwgaOA+vsJMjNczybvMDOQQEnsGQUv44vYfVsoKgdaYNFrQgOZECT6BhC6za0s+kjGgDiNIsZJ9g0t8us1G9hA1VBYAr1MYM7P882ueXn2iAX4jlJLjs3j9omx/b71Isue/ndBGvDoL7AVmPMdqcQHwHjAK8BApgAPBbA8iilaoqQkMKRWvVb2NV/x7xgF3DMybBf1JFNPb+YjbFfxhJS+Mg7aWsa6QfsUvQnDtqhw5lHbb/JycKaS7O6WXBkG+w7ZpvETiXgSGjxsuTnFi7nUiA8EmrXt81l2enUzkqz/UFRLeA+/y9tEsgA0QpwD9fJQD9vGUXkDKAd4N6wFiEiy4FcYKox5ksf504CJgG0bVvOBduUUtWfCDQ9q+TjRftRatW2iyaWZzHIvNzC6xYEm/T9hRtWZaQ6NZcsyM20AcFdSJid41Ir3AaQkycgO83Ows/NtIEiogFE1LeTHAMgkAHCWwOcr/as8cCnxniEy7bGmL0i0h74XkTWGGO2FbugMdOAaWCbmE630Eop5RdFR1fVqg2NzrCPKiKQO44nA+7TMFsDe33kHQ/McE8wxux1/m4HfgB6+7+ISimlfAlkgFgGdBSRdiISjg0CXxfNJCKdgUbAr25pjUSktvO8CTAQ330XSimlAiBgTUzGmFwRuQuYix3m+q4xZp2IPAksN8YUBIsJwEfGczjVWcBbIpKPDWJTfY1+UkopFRg6UU4ppWqwkoa5BrKJSSmlVBWmAUIppZRXGiCUUkp5pQFCKaWUV9Wqk1pEUoCd5Ty9CXDIj8WpyvReeNL7UUjvhafqcD/OMMbEeDtQrQLE6RCR5b568msavRee9H4U0nvhqbrfD21iUkop5ZUGCKWUUl5pgCg0LdgFqET0XnjS+1FI74Wnan0/tA9CKaWUV1qDUEop5ZUGCKWUUl7V+AAhIqNEZJOIbBWRKcEujz+JyLsiclBE1rqlNRaR+SKyxfnbyEkXEXnFuQ+JIhLvds4NTv4tInKDW3ofEVnjnPOK+GOX9gARkTYiskBENojIOhG5x0mvcfdDRCJEZKmIrHbuxRNOejsRWeJ8rv86y/QjIrWd11ud47Fu13rASd8kIhe4pVepf1ciEioiv4nITOd1jb0XHowxNfaBXYZ8G9AeCAdWA12DXS4/fr7BQDyw1i3teWCK83wK8Bfn+RhgNnYnwHOAJU56Y2C787eR87yRc2wp0N85ZzYwOtifuYR70QKId55HAZuBrjXxfjjli3SehwFLnM/4MTDeSX8TuN15fgfwpvN8PPBf53lX599MbeyWwducf1NV7t8VMBn4EJjpvK6x98L9UdNrEH2BrcaY7caYk8BHwLggl8lvjDELgcNFkscB/3Ke/wu4xC39fWMtBhqKSAvgAmC+MeawMeYIMB8Y5Ryrb4z51dh/Ie+7XavSMcbsM8asdJ6nAxuw+6bXuPvhfKbjzssw52GA84BPnfSi96LgHn0KDHdqR+Owe7lkG2N2AFux/6aq1L8rEWkNjAXedl4LNfReFFXTA0QrYLfb62QnrTprZozZB/ZLE2jqpPu6FyWlJ3tJr/ScZoHe2F/ONfJ+OE0qq4CD2CC3DThqjMl1sriX3/WZnePHgGhO/R5VVi8D9wP5zutoau698FDTA4S3NuKaOu7X17041fRKTUQigc+APxpj0krK6iWt2twPY0yeMaYXdq/4vthdHItlc/5W23shIhcCB40xK9yTvWSt9vfCm5oeIJKBNm6vWwN7g1SWinLAaQ7B+XvQSfd1L0pKb+0lvdISkTBscPjAGPO5k1xj7weAMeYo8AO2D6KhiBRsQ+xeftdndo43wDZdnuo9qowGAheLSBK2+ec8bI2iJt6L4oLdCRLMB3ZP7u3YTqWCDqRuwS6Xnz9jLJ6d1C/g2Sn7vPN8LJ6dskud9MbADmyHbCPneWPn2DInb0Gn7Jhgf94S7oNg+wVeLpJe4+4HEAM0dJ7XAX4CLgQ+wbNj9g7n+Z14dsx+7DzvhmfH7HZsp2yV/HcFDKWwk7pG3wvXPQl2AYL9wI5W2Yxtg30o2OXx82ebAewDcrC/ZG7Gtpd+B2xx/hZ8uQnwmnMf1gAJbte5CdvpthWY6JaeAKx1znkVZ2Z+ZXwAg7BV+0RglfMYUxPvBxAH/Obci7XAo056e+xIrK3OF2RtJz3Ceb3VOd7e7VoPOZ93E26jtqriv6siAaJG34uChy61oZRSyqua3gehlFLKBw0QSimlvNIAoZRSyisNEEoppbzSAKGUUsorDRCqShGRPBFZ5axEulJEBpSSv6GI3FGG6/4gItV28/nyEJH3ROSKYJdDBY8GCFXVZBpjehljegIPAM+Vkr8hdgXOSslttq5SlY4GCFWV1QeOgF1jSUS+c2oVa0SkYMXMqUAHp9bxgpP3fifPahGZ6na93zn7JGwWkXOdvKEi8oKILHP2hfi9k95CRBY6111bkN+diCSJyF+cay4VkTOd9PdE5CURWQD8ReyeFF86118sInFun2m6U9ZEEbncSR8pIr86n/UTZ30pRGSqiKx38r7opP3OKd9qEVlYymcSEXnVucYsChcuVDWU/npRVU0dZxXSCOweD+c56VnApcaYNBFpAiwWka+xy2d0N3ZhOkRkNHbp5n7GmAwRaex27VrGmL4iMgZ4DBiBnX1+zBhztojUBn4WkXnAZcBcY8wzIhIK1PVR3jTnmtdj1/i50EnvBIwwxuSJyD+A34wxl4jIedglQXoBjzjv3cMpeyPnsz3snHtCRP4PmCwirwKXAl2MMUZEGjrv8yhwgTFmj1uar8/UG+gM9ACaAeuBd8v0X0VVSxogVFWT6fZl3x94X0S6Y5fGeFZEBmOXbW6F/ZIragQw3RiTAWCMcd8vo2ABvxXYNawARgJxbm3xDYCO2HWX3nUWAPzSGLPKR3lnuP39m1v6J8aYPOf5IOBypzzfi0i0iDRwyjq+4ARjzBFn9dGu2C91sOv7/AqkYYPk286v/5nOaT8D74nIx26fz9dnGgzMcMq1V0S+9/GZVA2hAUJVWcaYX51f1DHY9W5igD7GmBxndc4IL6cJvpdbznb+5lH4b0OAPxhj5ha7kA1GY4F/i8gLxpj3vRXTx/MTRcrk7TxvZRXshkUTvJSnLzAcG1TuAs4zxtwmIv2ccq4SkV6+PpNTc9K1d5SL9kGoKktEumBXzEzF/go+6ASHYcAZTrZ07BajBeYBN4lIXeca7k1M3swFbndqCohIJxGpJyJnOO/3T+Ad7Nau3lzl9vdXH3kWAtc41x8KHDJ2r4p52C/6gs/bCFgMDHTrz6jrlCkSaGCM+Qb4I7aJChHpYIxZYox5FDiEXXra62dyyjHe6aNoAQwr5d6oak5rEKqqKeiDAPtL+AanHf8D4H8ishy7UutGAGNMqoj8LCJrgdnGmD87v6KXi8hJ4BvgwRLe721sc9NKsW06Kdg+jKHAn0UkBzgOXO/j/NoisgT7Y6zYr37H48B0EUkEMoAbnPSngdecsucBTxhjPheRG4EZTv8B2D6JdOArEYlw7su9zrEXRKSjk/YddrnpRB+f6Qtsn84a7OqjP5ZwX1QNoKu5KhUgTjNXgjHmULDLolR5aBOTUkopr7QGoZRSyiutQSillPJKA4RSSimvNEAopZTySgOEUkoprzRAKKWU8ur/ARq5jDM7E+OKAAAAAElFTkSuQmCC
"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="e80-results">e80 results<a class="anchor-link" href="#e80-results"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">acc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.903283</span><span class="p">,</span> <span class="mf">0.909392</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">acc</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">acc</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(0.9063375, 0.0030545000000000155)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

