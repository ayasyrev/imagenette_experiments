{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imagenette_experiments.train_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kornia.contrib import MaxBlurPool2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.basic_train import *\n",
    "from fastai.vision import *\n",
    "from model_constructor.net import Net, act_fn, NewResBlock\n",
    "from model_constructor.layers import SimpleSelfAttention, ConvLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# new Stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_stem_new(self):\n",
    "    '''new vers, 4 layers, stride on 1, groups'''\n",
    "#         stride_on=1\n",
    "#         stride_by_pool = False\n",
    "    stem = []\n",
    "    stem.append((f\"conv_0\", self.conv_layer(3,    32, stride=1, act_fn=self.act_fn, bn_1st=self.bn_1st)))\n",
    "    stem.append((f\"conv_1\", self.conv_layer(32,   64, stride=2, act_fn=self.act_fn, bn_1st=self.bn_1st)))\n",
    "    stem.append((f\"conv_2\", self.conv_layer(64,  128, stride=1, act_fn=self.act_fn, bn_1st=self.bn_1st,\n",
    "                                          groups=16,)))\n",
    "    stem.append((f\"conv_3\", self.conv_layer(128, 256, stride=1, act_fn=self.act_fn, bn_1st=self.bn_1st,\n",
    "                                          groups=32,)))\n",
    "#         if stride_by_pool:\n",
    "#             stem.insert(stride_on, ('reduce_stem', self.stem_pool))\n",
    "#             stem.insert(stride_on+1, ('reduce_bn', nn.BatchNorm2d(self.stem_sizes[stride_on])))\n",
    "    stem.append(('stem_pool', self.stem_pool))\n",
    "    if self.stem_bn_end: stem.append(('norm', self.norm(self.stem_sizes[-1])))\n",
    "    return nn.Sequential(OrderedDict(stem))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixup = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 192\n",
    "bs = 32\n",
    "epochs=80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(c_out=10, layers=[3,6,8,3], expansion=4)\n",
    "model.block = NewResBlock\n",
    "model.act_fn = Mish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._make_stem = _make_stem_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sa=True\n",
    "model.groups =4\n",
    "model.stem_sizes = [3,32,64,128,256]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv_0): ConvLayer(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act_fn): Mish()\n",
       "  )\n",
       "  (conv_1): ConvLayer(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act_fn): Mish()\n",
       "  )\n",
       "  (conv_2): ConvLayer(\n",
       "    (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act_fn): Mish()\n",
       "  )\n",
       "  (conv_3): ConvLayer(\n",
       "    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act_fn): Mish()\n",
       "  )\n",
       "  (stem_pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (l_0): Sequential(\n",
       "    (bl_0): NewResBlock(\n",
       "      (convs): Sequential(\n",
       "        (conv_0): ConvLayer(\n",
       "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_1): ConvLayer(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_2): ConvLayer(\n",
       "          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (merge): Mish()\n",
       "    )\n",
       "    (bl_1): NewResBlock(\n",
       "      (convs): Sequential(\n",
       "        (conv_0): ConvLayer(\n",
       "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_1): ConvLayer(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_2): ConvLayer(\n",
       "          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (merge): Mish()\n",
       "    )\n",
       "    (bl_2): NewResBlock(\n",
       "      (convs): Sequential(\n",
       "        (conv_0): ConvLayer(\n",
       "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_1): ConvLayer(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_2): ConvLayer(\n",
       "          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (sa): SimpleSelfAttention(\n",
       "          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (merge): Mish()\n",
       "    )\n",
       "  )\n",
       "  (l_1): Sequential(\n",
       "    (bl_0): NewResBlock(\n",
       "      (reduce): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (convs): Sequential(\n",
       "        (conv_0): ConvLayer(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_1): ConvLayer(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_2): ConvLayer(\n",
       "          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (idconv): ConvLayer(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (merge): Mish()\n",
       "    )\n",
       "    (bl_1): NewResBlock(\n",
       "      (convs): Sequential(\n",
       "        (conv_0): ConvLayer(\n",
       "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_1): ConvLayer(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_2): ConvLayer(\n",
       "          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (merge): Mish()\n",
       "    )\n",
       "    (bl_2): NewResBlock(\n",
       "      (convs): Sequential(\n",
       "        (conv_0): ConvLayer(\n",
       "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_1): ConvLayer(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_2): ConvLayer(\n",
       "          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (merge): Mish()\n",
       "    )\n",
       "    (bl_3): NewResBlock(\n",
       "      (convs): Sequential(\n",
       "        (conv_0): ConvLayer(\n",
       "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_1): ConvLayer(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_2): ConvLayer(\n",
       "          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (merge): Mish()\n",
       "    )\n",
       "    (bl_4): NewResBlock(\n",
       "      (convs): Sequential(\n",
       "        (conv_0): ConvLayer(\n",
       "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_1): ConvLayer(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_2): ConvLayer(\n",
       "          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (merge): Mish()\n",
       "    )\n",
       "    (bl_5): NewResBlock(\n",
       "      (convs): Sequential(\n",
       "        (conv_0): ConvLayer(\n",
       "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_1): ConvLayer(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_2): ConvLayer(\n",
       "          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (merge): Mish()\n",
       "    )\n",
       "  )\n",
       "  (l_2): Sequential(\n",
       "    (bl_0): NewResBlock(\n",
       "      (reduce): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (convs): Sequential(\n",
       "        (conv_0): ConvLayer(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_1): ConvLayer(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_2): ConvLayer(\n",
       "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (idconv): ConvLayer(\n",
       "        (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (merge): Mish()\n",
       "    )\n",
       "    (bl_1): NewResBlock(\n",
       "      (convs): Sequential(\n",
       "        (conv_0): ConvLayer(\n",
       "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_1): ConvLayer(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_2): ConvLayer(\n",
       "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (merge): Mish()\n",
       "    )\n",
       "    (bl_2): NewResBlock(\n",
       "      (convs): Sequential(\n",
       "        (conv_0): ConvLayer(\n",
       "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_1): ConvLayer(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_2): ConvLayer(\n",
       "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (merge): Mish()\n",
       "    )\n",
       "    (bl_3): NewResBlock(\n",
       "      (convs): Sequential(\n",
       "        (conv_0): ConvLayer(\n",
       "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_1): ConvLayer(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_2): ConvLayer(\n",
       "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (merge): Mish()\n",
       "    )\n",
       "    (bl_4): NewResBlock(\n",
       "      (convs): Sequential(\n",
       "        (conv_0): ConvLayer(\n",
       "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_1): ConvLayer(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_2): ConvLayer(\n",
       "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (merge): Mish()\n",
       "    )\n",
       "    (bl_5): NewResBlock(\n",
       "      (convs): Sequential(\n",
       "        (conv_0): ConvLayer(\n",
       "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_1): ConvLayer(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_2): ConvLayer(\n",
       "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (merge): Mish()\n",
       "    )\n",
       "    (bl_6): NewResBlock(\n",
       "      (convs): Sequential(\n",
       "        (conv_0): ConvLayer(\n",
       "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_1): ConvLayer(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_2): ConvLayer(\n",
       "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (merge): Mish()\n",
       "    )\n",
       "    (bl_7): NewResBlock(\n",
       "      (convs): Sequential(\n",
       "        (conv_0): ConvLayer(\n",
       "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_1): ConvLayer(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_2): ConvLayer(\n",
       "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (merge): Mish()\n",
       "    )\n",
       "  )\n",
       "  (l_3): Sequential(\n",
       "    (bl_0): NewResBlock(\n",
       "      (reduce): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (convs): Sequential(\n",
       "        (conv_0): ConvLayer(\n",
       "          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_1): ConvLayer(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_2): ConvLayer(\n",
       "          (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (idconv): ConvLayer(\n",
       "        (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (merge): Mish()\n",
       "    )\n",
       "    (bl_1): NewResBlock(\n",
       "      (convs): Sequential(\n",
       "        (conv_0): ConvLayer(\n",
       "          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_1): ConvLayer(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_2): ConvLayer(\n",
       "          (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (merge): Mish()\n",
       "    )\n",
       "    (bl_2): NewResBlock(\n",
       "      (convs): Sequential(\n",
       "        (conv_0): ConvLayer(\n",
       "          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_1): ConvLayer(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_fn): Mish()\n",
       "        )\n",
       "        (conv_2): ConvLayer(\n",
       "          (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (merge): Mish()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data path   /notebooks/data/imagewoof2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learn path /notebooks/data/imagewoof2\n"
     ]
    }
   ],
   "source": [
    "learn = get_learn(model=model, size=size, bs=bs, mixup=mixup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential\n",
       "======================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "======================================================================\n",
       "Conv2d               [32, 192, 192]       864        True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [32, 192, 192]       64         True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [64, 96, 96]         18,432     True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [64, 96, 96]         128        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [128, 96, 96]        4,608      True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [128, 96, 96]        256        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [256, 96, 96]        9,216      True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [256, 96, 96]        512        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "MaxPool2d            [256, 48, 48]        0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [64, 48, 48]         16,384     True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [64, 48, 48]         128        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [64, 48, 48]         2,304      True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [64, 48, 48]         128        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [256, 48, 48]        16,384     True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [256, 48, 48]        512        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [64, 48, 48]         16,384     True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [64, 48, 48]         128        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [64, 48, 48]         2,304      True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [64, 48, 48]         128        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [256, 48, 48]        16,384     True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [256, 48, 48]        512        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [64, 48, 48]         16,384     True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [64, 48, 48]         128        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [64, 48, 48]         2,304      True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [64, 48, 48]         128        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [256, 48, 48]        16,384     True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [256, 48, 48]        512        True      \n",
       "______________________________________________________________________\n",
       "Conv1d               [256, 2304]          65,536     True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "AvgPool2d            [1024, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [128, 24, 24]        32,768     True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [128, 24, 24]        256        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [128, 24, 24]        4,608      True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [128, 24, 24]        256        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [512, 24, 24]        65,536     True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [512, 24, 24]        1,024      True      \n",
       "______________________________________________________________________\n",
       "Conv2d               [512, 24, 24]        131,072    True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [512, 24, 24]        1,024      True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [128, 24, 24]        65,536     True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [128, 24, 24]        256        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [128, 24, 24]        4,608      True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [128, 24, 24]        256        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [512, 24, 24]        65,536     True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [512, 24, 24]        1,024      True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [128, 24, 24]        65,536     True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [128, 24, 24]        256        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [128, 24, 24]        4,608      True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [128, 24, 24]        256        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [512, 24, 24]        65,536     True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [512, 24, 24]        1,024      True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [128, 24, 24]        65,536     True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [128, 24, 24]        256        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [128, 24, 24]        4,608      True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [128, 24, 24]        256        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [512, 24, 24]        65,536     True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [512, 24, 24]        1,024      True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [128, 24, 24]        65,536     True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [128, 24, 24]        256        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [128, 24, 24]        4,608      True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [128, 24, 24]        256        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [512, 24, 24]        65,536     True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [512, 24, 24]        1,024      True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [128, 24, 24]        65,536     True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [128, 24, 24]        256        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [128, 24, 24]        4,608      True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [128, 24, 24]        256        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [512, 24, 24]        65,536     True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [512, 24, 24]        1,024      True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "AvgPool2d            [1024, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [256, 12, 12]        131,072    True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [256, 12, 12]        512        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [256, 12, 12]        9,216      True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [256, 12, 12]        512        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [1024, 12, 12]       262,144    True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [1024, 12, 12]       2,048      True      \n",
       "______________________________________________________________________\n",
       "Conv2d               [1024, 12, 12]       524,288    True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [1024, 12, 12]       2,048      True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [256, 12, 12]        262,144    True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [256, 12, 12]        512        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [256, 12, 12]        9,216      True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [256, 12, 12]        512        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [1024, 12, 12]       262,144    True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [1024, 12, 12]       2,048      True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [256, 12, 12]        262,144    True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [256, 12, 12]        512        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [256, 12, 12]        9,216      True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [256, 12, 12]        512        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [1024, 12, 12]       262,144    True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [1024, 12, 12]       2,048      True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [256, 12, 12]        262,144    True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [256, 12, 12]        512        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [256, 12, 12]        9,216      True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [256, 12, 12]        512        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [1024, 12, 12]       262,144    True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [1024, 12, 12]       2,048      True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [256, 12, 12]        262,144    True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [256, 12, 12]        512        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [256, 12, 12]        9,216      True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [256, 12, 12]        512        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [1024, 12, 12]       262,144    True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [1024, 12, 12]       2,048      True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [256, 12, 12]        262,144    True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [256, 12, 12]        512        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [256, 12, 12]        9,216      True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [256, 12, 12]        512        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [1024, 12, 12]       262,144    True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [1024, 12, 12]       2,048      True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [256, 12, 12]        262,144    True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [256, 12, 12]        512        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [256, 12, 12]        9,216      True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [256, 12, 12]        512        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [1024, 12, 12]       262,144    True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [1024, 12, 12]       2,048      True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [256, 12, 12]        262,144    True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [256, 12, 12]        512        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [256, 12, 12]        9,216      True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [256, 12, 12]        512        True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [1024, 12, 12]       262,144    True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [1024, 12, 12]       2,048      True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "AvgPool2d            [1024, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [512, 6, 6]          524,288    True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [512, 6, 6]          1,024      True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [512, 6, 6]          18,432     True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [512, 6, 6]          1,024      True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [2048, 6, 6]         1,048,576  True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [2048, 6, 6]         4,096      True      \n",
       "______________________________________________________________________\n",
       "Conv2d               [2048, 6, 6]         2,097,152  True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [2048, 6, 6]         4,096      True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [512, 6, 6]          1,048,576  True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [512, 6, 6]          1,024      True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [512, 6, 6]          18,432     True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [512, 6, 6]          1,024      True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [2048, 6, 6]         1,048,576  True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [2048, 6, 6]         4,096      True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [512, 6, 6]          1,048,576  True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [512, 6, 6]          1,024      True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [512, 6, 6]          18,432     True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [512, 6, 6]          1,024      True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [2048, 6, 6]         1,048,576  True      \n",
       "______________________________________________________________________\n",
       "BatchNorm2d          [2048, 6, 6]         4,096      True      \n",
       "______________________________________________________________________\n",
       "Mish                 [2048, 6, 6]         0          False     \n",
       "______________________________________________________________________\n",
       "AdaptiveAvgPool2d    [2048, 1, 1]         0          False     \n",
       "______________________________________________________________________\n",
       "Flatten              [2048]               0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [10]                 20,490     True      \n",
       "______________________________________________________________________\n",
       "\n",
       "Total params: 13,780,266\n",
       "Total trainable params: 13,780,266\n",
       "Total non-trainable params: 0\n",
       "Optimized with 'imagenette_experiments.train_utils.Ranger', betas=(0.95, 0.99), eps=1e-06\n",
       "Using true weight decay as discussed in https://www.fast.ai/2018/07/02/adam-weight-decay/ \n",
       "Loss function : LabelSmoothingCrossEntropy\n",
       "======================================================================\n",
       "Callbacks functions applied "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lr find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>top_k_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='92' class='' max='282', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      32.62% [92/282 00:41<01:25 8.0256]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1591914855613/work/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of addcmul_ is deprecated:\n",
      "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set state called\n",
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pct start = 0.5 9011 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data path   /notebooks/data/imagewoof2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learn path /notebooks/data/imagewoof2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>top_k_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.045181</td>\n",
       "      <td>1.834633</td>\n",
       "      <td>0.403665</td>\n",
       "      <td>0.882922</td>\n",
       "      <td>02:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.811513</td>\n",
       "      <td>1.591556</td>\n",
       "      <td>0.528888</td>\n",
       "      <td>0.927971</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.662277</td>\n",
       "      <td>1.426720</td>\n",
       "      <td>0.598880</td>\n",
       "      <td>0.948842</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.522423</td>\n",
       "      <td>1.249655</td>\n",
       "      <td>0.691779</td>\n",
       "      <td>0.958005</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.458905</td>\n",
       "      <td>1.197891</td>\n",
       "      <td>0.715195</td>\n",
       "      <td>0.964877</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.392023</td>\n",
       "      <td>1.110638</td>\n",
       "      <td>0.759226</td>\n",
       "      <td>0.971749</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.318535</td>\n",
       "      <td>1.069143</td>\n",
       "      <td>0.774497</td>\n",
       "      <td>0.975057</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.308643</td>\n",
       "      <td>1.026081</td>\n",
       "      <td>0.796131</td>\n",
       "      <td>0.977093</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.248607</td>\n",
       "      <td>0.978242</td>\n",
       "      <td>0.817256</td>\n",
       "      <td>0.979893</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.253049</td>\n",
       "      <td>0.980652</td>\n",
       "      <td>0.808348</td>\n",
       "      <td>0.982184</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.207947</td>\n",
       "      <td>0.922024</td>\n",
       "      <td>0.839399</td>\n",
       "      <td>0.984220</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.191577</td>\n",
       "      <td>0.907299</td>\n",
       "      <td>0.849835</td>\n",
       "      <td>0.986256</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.193465</td>\n",
       "      <td>0.901824</td>\n",
       "      <td>0.846780</td>\n",
       "      <td>0.984220</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.121481</td>\n",
       "      <td>0.911739</td>\n",
       "      <td>0.840672</td>\n",
       "      <td>0.982947</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.115846</td>\n",
       "      <td>0.920421</td>\n",
       "      <td>0.842199</td>\n",
       "      <td>0.984729</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.108143</td>\n",
       "      <td>0.878778</td>\n",
       "      <td>0.851362</td>\n",
       "      <td>0.982947</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.087702</td>\n",
       "      <td>0.879662</td>\n",
       "      <td>0.849580</td>\n",
       "      <td>0.986002</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.062181</td>\n",
       "      <td>0.865078</td>\n",
       "      <td>0.861033</td>\n",
       "      <td>0.983456</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.069316</td>\n",
       "      <td>0.861220</td>\n",
       "      <td>0.860270</td>\n",
       "      <td>0.984983</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.045414</td>\n",
       "      <td>0.865800</td>\n",
       "      <td>0.857216</td>\n",
       "      <td>0.984474</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.059686</td>\n",
       "      <td>0.867996</td>\n",
       "      <td>0.849835</td>\n",
       "      <td>0.985238</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.033195</td>\n",
       "      <td>0.868259</td>\n",
       "      <td>0.854416</td>\n",
       "      <td>0.982184</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.022621</td>\n",
       "      <td>0.844940</td>\n",
       "      <td>0.867905</td>\n",
       "      <td>0.987529</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.017510</td>\n",
       "      <td>0.856082</td>\n",
       "      <td>0.863069</td>\n",
       "      <td>0.984983</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.993454</td>\n",
       "      <td>0.843708</td>\n",
       "      <td>0.863069</td>\n",
       "      <td>0.987529</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.019089</td>\n",
       "      <td>0.846209</td>\n",
       "      <td>0.866887</td>\n",
       "      <td>0.982693</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.996386</td>\n",
       "      <td>0.887620</td>\n",
       "      <td>0.858488</td>\n",
       "      <td>0.982184</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.973767</td>\n",
       "      <td>0.871253</td>\n",
       "      <td>0.861797</td>\n",
       "      <td>0.983965</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.993338</td>\n",
       "      <td>0.842008</td>\n",
       "      <td>0.868923</td>\n",
       "      <td>0.982693</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.958539</td>\n",
       "      <td>0.851311</td>\n",
       "      <td>0.866887</td>\n",
       "      <td>0.982184</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.957896</td>\n",
       "      <td>0.842967</td>\n",
       "      <td>0.867396</td>\n",
       "      <td>0.984983</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.958635</td>\n",
       "      <td>0.837996</td>\n",
       "      <td>0.875032</td>\n",
       "      <td>0.982947</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.968870</td>\n",
       "      <td>0.822992</td>\n",
       "      <td>0.876813</td>\n",
       "      <td>0.985238</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.959011</td>\n",
       "      <td>0.845953</td>\n",
       "      <td>0.863578</td>\n",
       "      <td>0.983456</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.950759</td>\n",
       "      <td>0.825917</td>\n",
       "      <td>0.875795</td>\n",
       "      <td>0.984220</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.932296</td>\n",
       "      <td>0.848019</td>\n",
       "      <td>0.866378</td>\n",
       "      <td>0.982438</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.939574</td>\n",
       "      <td>0.827895</td>\n",
       "      <td>0.879104</td>\n",
       "      <td>0.982438</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.948906</td>\n",
       "      <td>0.834699</td>\n",
       "      <td>0.868923</td>\n",
       "      <td>0.986002</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.932423</td>\n",
       "      <td>0.833498</td>\n",
       "      <td>0.877322</td>\n",
       "      <td>0.979384</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.918544</td>\n",
       "      <td>0.833105</td>\n",
       "      <td>0.869178</td>\n",
       "      <td>0.985747</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.910674</td>\n",
       "      <td>0.842300</td>\n",
       "      <td>0.870450</td>\n",
       "      <td>0.980657</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.924431</td>\n",
       "      <td>0.825433</td>\n",
       "      <td>0.871469</td>\n",
       "      <td>0.984474</td>\n",
       "      <td>02:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.914254</td>\n",
       "      <td>0.823391</td>\n",
       "      <td>0.877322</td>\n",
       "      <td>0.983965</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.903091</td>\n",
       "      <td>0.849424</td>\n",
       "      <td>0.864088</td>\n",
       "      <td>0.981420</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.917821</td>\n",
       "      <td>0.832959</td>\n",
       "      <td>0.869178</td>\n",
       "      <td>0.985238</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.891036</td>\n",
       "      <td>0.816369</td>\n",
       "      <td>0.876304</td>\n",
       "      <td>0.986256</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.897270</td>\n",
       "      <td>0.818660</td>\n",
       "      <td>0.880122</td>\n",
       "      <td>0.984474</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.908652</td>\n",
       "      <td>0.836216</td>\n",
       "      <td>0.872487</td>\n",
       "      <td>0.979893</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.879853</td>\n",
       "      <td>0.829827</td>\n",
       "      <td>0.879613</td>\n",
       "      <td>0.986256</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.889838</td>\n",
       "      <td>0.805889</td>\n",
       "      <td>0.884194</td>\n",
       "      <td>0.980402</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.881354</td>\n",
       "      <td>0.790307</td>\n",
       "      <td>0.888267</td>\n",
       "      <td>0.984474</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.872256</td>\n",
       "      <td>0.807122</td>\n",
       "      <td>0.882922</td>\n",
       "      <td>0.982438</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.863868</td>\n",
       "      <td>0.798050</td>\n",
       "      <td>0.889285</td>\n",
       "      <td>0.982184</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.852124</td>\n",
       "      <td>0.801389</td>\n",
       "      <td>0.884703</td>\n",
       "      <td>0.982947</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.876562</td>\n",
       "      <td>0.803007</td>\n",
       "      <td>0.888521</td>\n",
       "      <td>0.980402</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.872068</td>\n",
       "      <td>0.796689</td>\n",
       "      <td>0.890048</td>\n",
       "      <td>0.982947</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.843166</td>\n",
       "      <td>0.800733</td>\n",
       "      <td>0.883176</td>\n",
       "      <td>0.981929</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.852189</td>\n",
       "      <td>0.791507</td>\n",
       "      <td>0.892339</td>\n",
       "      <td>0.986765</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.846219</td>\n",
       "      <td>0.792151</td>\n",
       "      <td>0.888776</td>\n",
       "      <td>0.983456</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.854162</td>\n",
       "      <td>0.807567</td>\n",
       "      <td>0.880631</td>\n",
       "      <td>0.984729</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.830859</td>\n",
       "      <td>0.800830</td>\n",
       "      <td>0.890048</td>\n",
       "      <td>0.980402</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.834249</td>\n",
       "      <td>0.785987</td>\n",
       "      <td>0.891575</td>\n",
       "      <td>0.982184</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.836610</td>\n",
       "      <td>0.783583</td>\n",
       "      <td>0.890048</td>\n",
       "      <td>0.984729</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.820343</td>\n",
       "      <td>0.790042</td>\n",
       "      <td>0.892084</td>\n",
       "      <td>0.982184</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.818813</td>\n",
       "      <td>0.773612</td>\n",
       "      <td>0.897938</td>\n",
       "      <td>0.984474</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.824331</td>\n",
       "      <td>0.767085</td>\n",
       "      <td>0.897429</td>\n",
       "      <td>0.988038</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.817338</td>\n",
       "      <td>0.768964</td>\n",
       "      <td>0.895648</td>\n",
       "      <td>0.986256</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.803318</td>\n",
       "      <td>0.761426</td>\n",
       "      <td>0.899975</td>\n",
       "      <td>0.984983</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.810316</td>\n",
       "      <td>0.765977</td>\n",
       "      <td>0.903029</td>\n",
       "      <td>0.984983</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.802713</td>\n",
       "      <td>0.770882</td>\n",
       "      <td>0.899720</td>\n",
       "      <td>0.983456</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.809246</td>\n",
       "      <td>0.765783</td>\n",
       "      <td>0.900738</td>\n",
       "      <td>0.983711</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.797996</td>\n",
       "      <td>0.759076</td>\n",
       "      <td>0.900993</td>\n",
       "      <td>0.983711</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.803654</td>\n",
       "      <td>0.757653</td>\n",
       "      <td>0.902011</td>\n",
       "      <td>0.984983</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.804234</td>\n",
       "      <td>0.758980</td>\n",
       "      <td>0.901502</td>\n",
       "      <td>0.984729</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.797729</td>\n",
       "      <td>0.756159</td>\n",
       "      <td>0.902774</td>\n",
       "      <td>0.986765</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.806790</td>\n",
       "      <td>0.754711</td>\n",
       "      <td>0.902011</td>\n",
       "      <td>0.985747</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.808578</td>\n",
       "      <td>0.756501</td>\n",
       "      <td>0.901756</td>\n",
       "      <td>0.984983</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.797100</td>\n",
       "      <td>0.753871</td>\n",
       "      <td>0.902520</td>\n",
       "      <td>0.985492</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.795132</td>\n",
       "      <td>0.755204</td>\n",
       "      <td>0.901502</td>\n",
       "      <td>0.986002</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.806665</td>\n",
       "      <td>0.755236</td>\n",
       "      <td>0.900993</td>\n",
       "      <td>0.985492</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = get_learn(model=model, size=size, bs=bs, mixup=mixup)\n",
    "learn.fit_fc(epochs, lr=4e-3, moms=(0.95,0.95), start_pct=0.5)\n",
    "res += [learn.recorder.metrics[-1][0].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data path   /notebooks/data/imagewoof2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learn path /notebooks/data/imagewoof2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>top_k_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.051938</td>\n",
       "      <td>1.873728</td>\n",
       "      <td>0.406974</td>\n",
       "      <td>0.854925</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.822254</td>\n",
       "      <td>1.561403</td>\n",
       "      <td>0.547977</td>\n",
       "      <td>0.919063</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.695190</td>\n",
       "      <td>1.427811</td>\n",
       "      <td>0.597353</td>\n",
       "      <td>0.949096</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.544489</td>\n",
       "      <td>1.275470</td>\n",
       "      <td>0.682871</td>\n",
       "      <td>0.958259</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.451445</td>\n",
       "      <td>1.165354</td>\n",
       "      <td>0.738865</td>\n",
       "      <td>0.967676</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.399176</td>\n",
       "      <td>1.108733</td>\n",
       "      <td>0.762789</td>\n",
       "      <td>0.974294</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.325909</td>\n",
       "      <td>1.073325</td>\n",
       "      <td>0.770934</td>\n",
       "      <td>0.974294</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.320318</td>\n",
       "      <td>1.017468</td>\n",
       "      <td>0.793077</td>\n",
       "      <td>0.978366</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.257514</td>\n",
       "      <td>0.985596</td>\n",
       "      <td>0.807585</td>\n",
       "      <td>0.978621</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.234191</td>\n",
       "      <td>0.960094</td>\n",
       "      <td>0.819547</td>\n",
       "      <td>0.979893</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.223505</td>\n",
       "      <td>0.953447</td>\n",
       "      <td>0.827182</td>\n",
       "      <td>0.981420</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.193885</td>\n",
       "      <td>0.937059</td>\n",
       "      <td>0.832527</td>\n",
       "      <td>0.983711</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.169674</td>\n",
       "      <td>0.924975</td>\n",
       "      <td>0.833545</td>\n",
       "      <td>0.979893</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.148106</td>\n",
       "      <td>0.901237</td>\n",
       "      <td>0.845253</td>\n",
       "      <td>0.983711</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.129253</td>\n",
       "      <td>0.905777</td>\n",
       "      <td>0.842708</td>\n",
       "      <td>0.981929</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.099361</td>\n",
       "      <td>0.880970</td>\n",
       "      <td>0.850853</td>\n",
       "      <td>0.989056</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.085118</td>\n",
       "      <td>0.883634</td>\n",
       "      <td>0.846271</td>\n",
       "      <td>0.987274</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.090588</td>\n",
       "      <td>0.869809</td>\n",
       "      <td>0.854416</td>\n",
       "      <td>0.985492</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.063198</td>\n",
       "      <td>0.894150</td>\n",
       "      <td>0.850344</td>\n",
       "      <td>0.980148</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.062023</td>\n",
       "      <td>0.885297</td>\n",
       "      <td>0.851616</td>\n",
       "      <td>0.983711</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.049070</td>\n",
       "      <td>0.871108</td>\n",
       "      <td>0.852380</td>\n",
       "      <td>0.983711</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.033408</td>\n",
       "      <td>0.876247</td>\n",
       "      <td>0.857470</td>\n",
       "      <td>0.982184</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.019766</td>\n",
       "      <td>0.872899</td>\n",
       "      <td>0.855179</td>\n",
       "      <td>0.985747</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.005503</td>\n",
       "      <td>0.842348</td>\n",
       "      <td>0.870196</td>\n",
       "      <td>0.988038</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.011394</td>\n",
       "      <td>0.867890</td>\n",
       "      <td>0.854670</td>\n",
       "      <td>0.985492</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.967244</td>\n",
       "      <td>0.843571</td>\n",
       "      <td>0.863578</td>\n",
       "      <td>0.984983</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.987668</td>\n",
       "      <td>0.872912</td>\n",
       "      <td>0.858743</td>\n",
       "      <td>0.982438</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.987450</td>\n",
       "      <td>0.843744</td>\n",
       "      <td>0.867905</td>\n",
       "      <td>0.984729</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.966964</td>\n",
       "      <td>0.860233</td>\n",
       "      <td>0.860779</td>\n",
       "      <td>0.983202</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.967724</td>\n",
       "      <td>0.830524</td>\n",
       "      <td>0.868414</td>\n",
       "      <td>0.983456</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.978130</td>\n",
       "      <td>0.856896</td>\n",
       "      <td>0.860015</td>\n",
       "      <td>0.983965</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.950534</td>\n",
       "      <td>0.840971</td>\n",
       "      <td>0.868414</td>\n",
       "      <td>0.987274</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.936864</td>\n",
       "      <td>0.843125</td>\n",
       "      <td>0.866124</td>\n",
       "      <td>0.984220</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.948351</td>\n",
       "      <td>0.848127</td>\n",
       "      <td>0.867396</td>\n",
       "      <td>0.983202</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.951539</td>\n",
       "      <td>0.841633</td>\n",
       "      <td>0.870960</td>\n",
       "      <td>0.985238</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.919313</td>\n",
       "      <td>0.842898</td>\n",
       "      <td>0.868414</td>\n",
       "      <td>0.982947</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.948258</td>\n",
       "      <td>0.837961</td>\n",
       "      <td>0.869178</td>\n",
       "      <td>0.982947</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.943691</td>\n",
       "      <td>0.835102</td>\n",
       "      <td>0.875286</td>\n",
       "      <td>0.982438</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.931495</td>\n",
       "      <td>0.852099</td>\n",
       "      <td>0.862051</td>\n",
       "      <td>0.983965</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.939981</td>\n",
       "      <td>0.849955</td>\n",
       "      <td>0.866633</td>\n",
       "      <td>0.983965</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.918055</td>\n",
       "      <td>0.832519</td>\n",
       "      <td>0.874268</td>\n",
       "      <td>0.978875</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.930225</td>\n",
       "      <td>0.857439</td>\n",
       "      <td>0.864597</td>\n",
       "      <td>0.981166</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.914549</td>\n",
       "      <td>0.840021</td>\n",
       "      <td>0.864597</td>\n",
       "      <td>0.981166</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.922716</td>\n",
       "      <td>0.833835</td>\n",
       "      <td>0.871978</td>\n",
       "      <td>0.986256</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.895460</td>\n",
       "      <td>0.837564</td>\n",
       "      <td>0.865360</td>\n",
       "      <td>0.980148</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.901493</td>\n",
       "      <td>0.835531</td>\n",
       "      <td>0.868414</td>\n",
       "      <td>0.981420</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.901322</td>\n",
       "      <td>0.835668</td>\n",
       "      <td>0.872741</td>\n",
       "      <td>0.981420</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.890591</td>\n",
       "      <td>0.840296</td>\n",
       "      <td>0.869178</td>\n",
       "      <td>0.981929</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.898077</td>\n",
       "      <td>0.810719</td>\n",
       "      <td>0.882667</td>\n",
       "      <td>0.985238</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.884179</td>\n",
       "      <td>0.815805</td>\n",
       "      <td>0.875286</td>\n",
       "      <td>0.984729</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.881287</td>\n",
       "      <td>0.823147</td>\n",
       "      <td>0.881140</td>\n",
       "      <td>0.983202</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.887501</td>\n",
       "      <td>0.821356</td>\n",
       "      <td>0.878850</td>\n",
       "      <td>0.982184</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.865062</td>\n",
       "      <td>0.789738</td>\n",
       "      <td>0.888776</td>\n",
       "      <td>0.986765</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.872829</td>\n",
       "      <td>0.802004</td>\n",
       "      <td>0.882922</td>\n",
       "      <td>0.984220</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.862655</td>\n",
       "      <td>0.803306</td>\n",
       "      <td>0.885467</td>\n",
       "      <td>0.985492</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.868537</td>\n",
       "      <td>0.804393</td>\n",
       "      <td>0.882413</td>\n",
       "      <td>0.985238</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.856287</td>\n",
       "      <td>0.802170</td>\n",
       "      <td>0.884958</td>\n",
       "      <td>0.983202</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.855480</td>\n",
       "      <td>0.798660</td>\n",
       "      <td>0.883431</td>\n",
       "      <td>0.984729</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.836637</td>\n",
       "      <td>0.781939</td>\n",
       "      <td>0.889030</td>\n",
       "      <td>0.984729</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.827330</td>\n",
       "      <td>0.791071</td>\n",
       "      <td>0.889285</td>\n",
       "      <td>0.984220</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.824191</td>\n",
       "      <td>0.786625</td>\n",
       "      <td>0.892084</td>\n",
       "      <td>0.982693</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.843770</td>\n",
       "      <td>0.785900</td>\n",
       "      <td>0.887758</td>\n",
       "      <td>0.986002</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.838230</td>\n",
       "      <td>0.776683</td>\n",
       "      <td>0.898193</td>\n",
       "      <td>0.986765</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.829090</td>\n",
       "      <td>0.773251</td>\n",
       "      <td>0.895139</td>\n",
       "      <td>0.984983</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.820267</td>\n",
       "      <td>0.774321</td>\n",
       "      <td>0.895648</td>\n",
       "      <td>0.985492</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.814170</td>\n",
       "      <td>0.770894</td>\n",
       "      <td>0.896411</td>\n",
       "      <td>0.983202</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.799237</td>\n",
       "      <td>0.776357</td>\n",
       "      <td>0.896666</td>\n",
       "      <td>0.981675</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.812712</td>\n",
       "      <td>0.770805</td>\n",
       "      <td>0.896920</td>\n",
       "      <td>0.982184</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.807340</td>\n",
       "      <td>0.764545</td>\n",
       "      <td>0.899720</td>\n",
       "      <td>0.985747</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.811225</td>\n",
       "      <td>0.765058</td>\n",
       "      <td>0.898447</td>\n",
       "      <td>0.985238</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.810093</td>\n",
       "      <td>0.761666</td>\n",
       "      <td>0.900229</td>\n",
       "      <td>0.984220</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.801765</td>\n",
       "      <td>0.758072</td>\n",
       "      <td>0.900738</td>\n",
       "      <td>0.985747</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.798103</td>\n",
       "      <td>0.755927</td>\n",
       "      <td>0.901756</td>\n",
       "      <td>0.984729</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.807387</td>\n",
       "      <td>0.755001</td>\n",
       "      <td>0.899466</td>\n",
       "      <td>0.984729</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.785985</td>\n",
       "      <td>0.756629</td>\n",
       "      <td>0.901756</td>\n",
       "      <td>0.984474</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.822407</td>\n",
       "      <td>0.756873</td>\n",
       "      <td>0.901247</td>\n",
       "      <td>0.983711</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.790082</td>\n",
       "      <td>0.755382</td>\n",
       "      <td>0.900484</td>\n",
       "      <td>0.986002</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.798734</td>\n",
       "      <td>0.756778</td>\n",
       "      <td>0.899720</td>\n",
       "      <td>0.984220</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.787715</td>\n",
       "      <td>0.755330</td>\n",
       "      <td>0.901502</td>\n",
       "      <td>0.984729</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.807383</td>\n",
       "      <td>0.755995</td>\n",
       "      <td>0.901247</td>\n",
       "      <td>0.985747</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = get_learn(model=model, size=size, bs=bs, mixup=mixup)\n",
    "learn.fit_fc(epochs, lr=4e-3, moms=(0.95,0.95), start_pct=0.5)\n",
    "res += [learn.recorder.metrics[-1][0].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### res 9011 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9009926319122314, 0.9012471437454224]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9011198878288269, 0.00012725591659545898)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat.mean(), stat.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pct start =  0.4 9027"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data path   /notebooks/data/imagewoof2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learn path /notebooks/data/imagewoof2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>top_k_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.028447</td>\n",
       "      <td>1.816024</td>\n",
       "      <td>0.418173</td>\n",
       "      <td>0.866378</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.803714</td>\n",
       "      <td>1.524516</td>\n",
       "      <td>0.548486</td>\n",
       "      <td>0.928481</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.652679</td>\n",
       "      <td>1.393331</td>\n",
       "      <td>0.619496</td>\n",
       "      <td>0.947569</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.539977</td>\n",
       "      <td>1.200333</td>\n",
       "      <td>0.712395</td>\n",
       "      <td>0.968949</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.449986</td>\n",
       "      <td>1.159575</td>\n",
       "      <td>0.728175</td>\n",
       "      <td>0.969458</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.365767</td>\n",
       "      <td>1.097864</td>\n",
       "      <td>0.768898</td>\n",
       "      <td>0.971494</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.319454</td>\n",
       "      <td>1.048688</td>\n",
       "      <td>0.786714</td>\n",
       "      <td>0.977093</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.316811</td>\n",
       "      <td>1.076991</td>\n",
       "      <td>0.769661</td>\n",
       "      <td>0.976330</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.247685</td>\n",
       "      <td>0.977651</td>\n",
       "      <td>0.813184</td>\n",
       "      <td>0.978366</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.216128</td>\n",
       "      <td>0.961996</td>\n",
       "      <td>0.820820</td>\n",
       "      <td>0.982693</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.190519</td>\n",
       "      <td>0.942688</td>\n",
       "      <td>0.827437</td>\n",
       "      <td>0.981675</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.157815</td>\n",
       "      <td>0.937077</td>\n",
       "      <td>0.830746</td>\n",
       "      <td>0.980148</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.135175</td>\n",
       "      <td>0.915857</td>\n",
       "      <td>0.835582</td>\n",
       "      <td>0.982438</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.133943</td>\n",
       "      <td>0.896118</td>\n",
       "      <td>0.851871</td>\n",
       "      <td>0.983202</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.103182</td>\n",
       "      <td>0.888727</td>\n",
       "      <td>0.843217</td>\n",
       "      <td>0.982947</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.091285</td>\n",
       "      <td>0.904667</td>\n",
       "      <td>0.849071</td>\n",
       "      <td>0.979893</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.083763</td>\n",
       "      <td>0.871688</td>\n",
       "      <td>0.858743</td>\n",
       "      <td>0.982184</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.076977</td>\n",
       "      <td>0.878374</td>\n",
       "      <td>0.854416</td>\n",
       "      <td>0.983711</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.044080</td>\n",
       "      <td>0.891524</td>\n",
       "      <td>0.849071</td>\n",
       "      <td>0.982947</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.055094</td>\n",
       "      <td>0.877115</td>\n",
       "      <td>0.860524</td>\n",
       "      <td>0.985747</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.042285</td>\n",
       "      <td>0.868252</td>\n",
       "      <td>0.854925</td>\n",
       "      <td>0.983965</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.022634</td>\n",
       "      <td>0.854551</td>\n",
       "      <td>0.864597</td>\n",
       "      <td>0.982947</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.016828</td>\n",
       "      <td>0.861434</td>\n",
       "      <td>0.865106</td>\n",
       "      <td>0.983456</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.006730</td>\n",
       "      <td>0.867302</td>\n",
       "      <td>0.856707</td>\n",
       "      <td>0.981675</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.007115</td>\n",
       "      <td>0.853897</td>\n",
       "      <td>0.865869</td>\n",
       "      <td>0.984220</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.012339</td>\n",
       "      <td>0.886153</td>\n",
       "      <td>0.852380</td>\n",
       "      <td>0.984220</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.977648</td>\n",
       "      <td>0.863209</td>\n",
       "      <td>0.853398</td>\n",
       "      <td>0.982438</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.982723</td>\n",
       "      <td>0.855266</td>\n",
       "      <td>0.863578</td>\n",
       "      <td>0.983456</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.971683</td>\n",
       "      <td>0.853870</td>\n",
       "      <td>0.868923</td>\n",
       "      <td>0.981929</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.964474</td>\n",
       "      <td>0.843517</td>\n",
       "      <td>0.871214</td>\n",
       "      <td>0.984983</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.956787</td>\n",
       "      <td>0.846873</td>\n",
       "      <td>0.872232</td>\n",
       "      <td>0.980402</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.953953</td>\n",
       "      <td>0.861445</td>\n",
       "      <td>0.869178</td>\n",
       "      <td>0.982438</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.939388</td>\n",
       "      <td>0.851869</td>\n",
       "      <td>0.866124</td>\n",
       "      <td>0.981166</td>\n",
       "      <td>02:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.961168</td>\n",
       "      <td>0.847084</td>\n",
       "      <td>0.867651</td>\n",
       "      <td>0.985238</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.938148</td>\n",
       "      <td>0.849705</td>\n",
       "      <td>0.866633</td>\n",
       "      <td>0.981929</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.924944</td>\n",
       "      <td>0.828885</td>\n",
       "      <td>0.875032</td>\n",
       "      <td>0.981166</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.926851</td>\n",
       "      <td>0.845178</td>\n",
       "      <td>0.869432</td>\n",
       "      <td>0.982693</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.909423</td>\n",
       "      <td>0.828286</td>\n",
       "      <td>0.872487</td>\n",
       "      <td>0.985238</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.923371</td>\n",
       "      <td>0.844364</td>\n",
       "      <td>0.866887</td>\n",
       "      <td>0.983965</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.906969</td>\n",
       "      <td>0.826410</td>\n",
       "      <td>0.878595</td>\n",
       "      <td>0.984220</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.906612</td>\n",
       "      <td>0.837736</td>\n",
       "      <td>0.872996</td>\n",
       "      <td>0.981675</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.904611</td>\n",
       "      <td>0.837549</td>\n",
       "      <td>0.869432</td>\n",
       "      <td>0.980911</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.907530</td>\n",
       "      <td>0.823261</td>\n",
       "      <td>0.873505</td>\n",
       "      <td>0.980911</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.880005</td>\n",
       "      <td>0.810713</td>\n",
       "      <td>0.881904</td>\n",
       "      <td>0.982947</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.891656</td>\n",
       "      <td>0.817219</td>\n",
       "      <td>0.884703</td>\n",
       "      <td>0.982947</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.906695</td>\n",
       "      <td>0.822082</td>\n",
       "      <td>0.876559</td>\n",
       "      <td>0.985238</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.868389</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.873759</td>\n",
       "      <td>0.983202</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.874326</td>\n",
       "      <td>0.819510</td>\n",
       "      <td>0.883940</td>\n",
       "      <td>0.982438</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.879052</td>\n",
       "      <td>0.834737</td>\n",
       "      <td>0.870450</td>\n",
       "      <td>0.982438</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.864259</td>\n",
       "      <td>0.815164</td>\n",
       "      <td>0.880886</td>\n",
       "      <td>0.981166</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.865417</td>\n",
       "      <td>0.811360</td>\n",
       "      <td>0.882413</td>\n",
       "      <td>0.981675</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.854655</td>\n",
       "      <td>0.813549</td>\n",
       "      <td>0.884449</td>\n",
       "      <td>0.978875</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.847375</td>\n",
       "      <td>0.810967</td>\n",
       "      <td>0.883940</td>\n",
       "      <td>0.982184</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.843257</td>\n",
       "      <td>0.812057</td>\n",
       "      <td>0.883431</td>\n",
       "      <td>0.981675</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.857747</td>\n",
       "      <td>0.804712</td>\n",
       "      <td>0.884703</td>\n",
       "      <td>0.979893</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.826775</td>\n",
       "      <td>0.795958</td>\n",
       "      <td>0.891321</td>\n",
       "      <td>0.980657</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.851101</td>\n",
       "      <td>0.798534</td>\n",
       "      <td>0.888267</td>\n",
       "      <td>0.980911</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.850925</td>\n",
       "      <td>0.811714</td>\n",
       "      <td>0.887249</td>\n",
       "      <td>0.978621</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.821906</td>\n",
       "      <td>0.788439</td>\n",
       "      <td>0.893103</td>\n",
       "      <td>0.979384</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.828395</td>\n",
       "      <td>0.783892</td>\n",
       "      <td>0.892084</td>\n",
       "      <td>0.982184</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.821412</td>\n",
       "      <td>0.811803</td>\n",
       "      <td>0.885976</td>\n",
       "      <td>0.980657</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.828258</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>0.887503</td>\n",
       "      <td>0.977857</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.808349</td>\n",
       "      <td>0.794727</td>\n",
       "      <td>0.889285</td>\n",
       "      <td>0.982947</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.813963</td>\n",
       "      <td>0.789903</td>\n",
       "      <td>0.897175</td>\n",
       "      <td>0.980402</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.812272</td>\n",
       "      <td>0.787422</td>\n",
       "      <td>0.893103</td>\n",
       "      <td>0.982438</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.810743</td>\n",
       "      <td>0.786190</td>\n",
       "      <td>0.897938</td>\n",
       "      <td>0.981675</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.814518</td>\n",
       "      <td>0.783077</td>\n",
       "      <td>0.897175</td>\n",
       "      <td>0.980657</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.809458</td>\n",
       "      <td>0.783035</td>\n",
       "      <td>0.896411</td>\n",
       "      <td>0.980148</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.797773</td>\n",
       "      <td>0.778476</td>\n",
       "      <td>0.895902</td>\n",
       "      <td>0.982947</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.803352</td>\n",
       "      <td>0.775102</td>\n",
       "      <td>0.900484</td>\n",
       "      <td>0.980657</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.795924</td>\n",
       "      <td>0.775537</td>\n",
       "      <td>0.901502</td>\n",
       "      <td>0.980911</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.804860</td>\n",
       "      <td>0.773240</td>\n",
       "      <td>0.900229</td>\n",
       "      <td>0.979384</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.798950</td>\n",
       "      <td>0.773967</td>\n",
       "      <td>0.899720</td>\n",
       "      <td>0.980657</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.813316</td>\n",
       "      <td>0.772153</td>\n",
       "      <td>0.899975</td>\n",
       "      <td>0.980402</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.804768</td>\n",
       "      <td>0.774734</td>\n",
       "      <td>0.901247</td>\n",
       "      <td>0.982184</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.799682</td>\n",
       "      <td>0.768956</td>\n",
       "      <td>0.900993</td>\n",
       "      <td>0.980657</td>\n",
       "      <td>02:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.795645</td>\n",
       "      <td>0.770725</td>\n",
       "      <td>0.902774</td>\n",
       "      <td>0.981420</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.807160</td>\n",
       "      <td>0.769518</td>\n",
       "      <td>0.904810</td>\n",
       "      <td>0.981420</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.795430</td>\n",
       "      <td>0.770018</td>\n",
       "      <td>0.902520</td>\n",
       "      <td>0.979893</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.813055</td>\n",
       "      <td>0.768678</td>\n",
       "      <td>0.902774</td>\n",
       "      <td>0.981420</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = get_learn(model=model, size=size, bs=bs, mixup=mixup)\n",
    "learn.fit_fc(epochs, lr=4e-3, moms=(0.95,0.95), start_pct=0.4)\n",
    "res += [learn.recorder.metrics[-1][0].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### res 9027"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9027742147445679]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat.mean(), stat.std()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 1
}
